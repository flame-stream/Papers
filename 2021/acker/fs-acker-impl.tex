\label {fs-acker-impl}

In the previous section, we introduced a general schema of the \tracker. In this section, we deepen into its implementation details. In the first section, we formally define the \textit{global time} labeling and explore its properties. The second section is dedicated to the \tracker\ agent algorithm. The next section focuses on the single node implementation of the \tracker\ agent and local \tracker\ optimization. Distributed implementation of the \tracker\ concludes this part.

\subsection{Global time}
In Section~\ref{sec:acker-analysis}, we have introduced the notion of \textit{global time}, without details of its practical implementation. One can use time oracle agent~\cite{10.14778/3055330.3055335} to generate a monotonic sequence of unique timestamps. However, in this case, the system will have a single point of failure. 

To make our system tolerant to the time difference between sources, we systematically synchronize the system clocks of them. We assume that clock differences are no more than some fixed $\delta$, which we reference as synchronization slack.

Let $\tau(d)$ be precise physical time of input data item $d$ arrival, and $s(d)$ be local system time of the source node where $d$ arrived. The true order of events $\tau(d_1) > \tau(d_2)$ coming from different sources can be sometimes restored by their system timestamps $s(d_1)$ and $s(d_2)$. If these timestamps differ more than time synchronization slack, then the order is clear: $s(d_1) > s(d_2) + \delta \Rightarrow \tau(d_1) > \tau(d_2)$.

This fact allows us to define \textit{global time} slots $gt(d)$ such that $gt(d) = [s(d) / \delta]$. This way we make global time less precise,  on one hand but this trick gives us ability to compare global time associated by different source nodes on the other. If global time of an item $d_1$ is greater by one than the global time of some other element $d_2$ then their order is defined despite the source nodes associated their labels:  $gt(d_1) > gt(d_2) + 1 \Rightarrow \tau(d_1) > \tau(d_2)$. This property forms a basis of our guarantees mechanism. Here is the summary of labeling mechanism:
\begin{enumerate}
    \item On receiving of input item, source node gets the system timestamp
    \item The system timestamp is shrunk up to synchronization slack (practically we use 10ms)
    \item The item is labeled by the result \textit{global time} and this label is sent to \tracker\ agent
\end{enumerate}

\subsection{Interface\ of\ \tracker\ }
\tracker\ agent has interface similar to Storm \acker, in a way that it receives \textit{ack} messages (\textit{global time} together with random \textit{ack value}) and subscribe/unsuscribe messages that is used to manage list of notifications subscribers. 

However, the \tracker\  interface has several distinctions. Firstly, \textit{ack} messages are extended with a \textit{segment} label that is needed to provide dataflow-local notifications. Secondly, data sources should send special messages called \textit{heartbeats} that contain \textit{global time}. It promises that the source will not generate elements with lower or equal \textit{global time}. These messages allow \tracker\ to send notifications even if some sources did not produce records with a specific \textit{global time} due to low traffic. 

\begin{algorithm}
\caption{\tracker\ implementation sketch}
\label{tracker_algo}
\begin{algorithmic}[1]
\State $inputs \leftarrow configured\_inputs;$ 
\State $subscribers \leftarrow configured\_subscribers;$
\State $segments \leftarrow List[Segment]$
\State $segmentChecksums \leftarrow Map[Segment, List[Int64]]$
\State $segmentMinTime \leftarrow Map[Segment, GlobalTime]$
\State $sourceHeartbeat \leftarrow Map[Source, GlobalTime]$
\\
\State \textbf{Upon} (segment, gt, ack\_val) $from \ in\in inputs$
\Indent
    \State $segmentChecksums[segment][gt] \gets $
    \par\Indent\Indent$segmentChecksums[segment][gt] \bigoplus checksum$\EndIndent\EndIndent
    \State $CheckMinTime$
\EndIndent
\\
\State \textbf{Upon} (gt, source) $from \ in\in inputs$
\Indent
 \State $sourceHeartbeat[source] \leftarrow gt$
 \State $CheckMinTime$
\EndIndent
\\
\Procedure{CheckMinTime}{}
\State $minHeartbeat \leftarrow sourceHeartbeat.values.min()$
\For {$segment \in segments$}
\State $checksums \gets segmentChecksums[segment]$
\State $maxTime \gets min($
\par\Indent\Indent$minHeartbeat,$\EndIndent\EndIndent
\par\Indent\Indent$segmentMinTime[segment.inbound].min(),$\EndIndent\EndIndent
\par\Indent$)$\EndIndent
\State $time \gets segmentMinTime[segment]$
\While{$time < maxTime$
\par\Indent$\And checksums[time] = 0$\EndIndent
\par}
\State $time \gets time + 1$
\EndWhile
\If{$segmentMinTime[segment] < time$}
\State $segmentMinTime[segment] \gets time$
\For {$subscriber \in subscribers$}
\State $subscriber.send(segment, time)$
\EndFor
\EndIf
\EndFor
\EndProcedure
\end{algorithmic}
\end{algorithm}

Therefore, \tracker\ receives the following messages:
\begin{itemize}
    \item Ack message is a tuple of a \textit{global time}, \textit{segment}, and \textit{ack value} (random number)
    \item Heartbeat message is a pair of a \textit{global time} and a source id.
    \item (Un)Subscribe message
\end{itemize}

% On ack message the accumulator, associated with provided \textit{global time} is updated by the received \textit{ack value}. Due to commutation of xor operation the checksum change may contain either single ack or multiple acks xored to a single change. The heartbeat message from source guarantees that no more input items with such a \textit{global time} will be emitted by this front-end. Subscribe messages manage the list of notification receivers. 

\tracker\ sends the following messages to subscribers:
\begin{itemize}
    \item \textit{Min segment time update} for time $t$ when no items with the \textit{global time} less or equal $t$ exists in the segment and all preceding segments are complete
    \item \textit{Min global time update} for time $t$ when no items with the \textit{global time} less or equal $t$ exists in the system
\end{itemize}

\textit{Min time update for segment} is emitted and send to all subscribers when:
\begin{enumerate}
    \item the \textit{heartbeat} for this time is received from all source nodes;
    \item accumulators for all \textit{global times} not greater than this time plus one\footnote{The condition from the previous section requires the completeness of the next global time segment to preserve the order of the input elements in the notifications stream} are nullified;
    \item upstream segments for this \textit{global time} have already sent \textit{min time updates}.
\end{enumerate}
If accumulators for all segments of a certain \textit{global time} become zero, \tracker\ sends \textit{min global time update}. An implementation sketch of \tracker\ interface is shown in Algorithm~\ref{tracker_algo}.

% \subsection{Centralized \tracker\ }

% \tracker\ is implemented as an "actor" on a dedicated machine and is shared between all system workers. It encapsulates minimal times received from the system fronts and a cyclic buffer for storing tracked elements.

% Cyclic buffer stores checksums keyed by elements Global Time windows. It stores values in a fixed size range starting from current Minimal Global Time window. \tracker\ applies received Ack messages checksum changes to the corresponding value stored in the buffer.

% \tracker\ can tell that there will be no more elements in a specific Global Time window when two conditions are fulfilled: no fronts will emit any more elements within this Global Time window and the cyclic buffer stores zero for it. Every time \tracker\ receives Acks or Heartbeats, it checks these conditions. If there are any matching windows \tracker removes them from the beginning of the buffer and broadcasts an update with the last of the windows.

% \begin{algorithm}
% \caption{\tracker}
% \begin{algorithmic}[1]
% \Procedure{HandleAck}{$time, checksum$}
% \State $checksums[time] \gets checksums[time] \bigoplus checksum$
% \State $CheckMinTime$
% \EndProcedure
% \\
% \Procedure{HandleHeartbeat}{$time$}
% \State $heartbeat \gets time$
% \State $CheckMinTime$
% \EndProcedure
% \\
% \Procedure{CheckMinTime}{}
% \State $time \gets previousMinTime$
% \While{$time < heartbeat \And checksums[time] = 0$}
% \State $time \gets time + 1$
% \EndWhile
% \If{$previousMinTime < time$}
% \State $previousMinTime \gets time$
% \State $SendMinTimeUpdate(time)$
% \EndIf
% \EndProcedure
% \end{algorithmic}
% \end{algorithm}

% To prevent false Min Time Updates this implementation has two requirements on order of processing:

% \begin{itemize}
%     \item Initial Ack message emitted from front with an input element must be processed before the following Heartbeat message.
%     \item When operator processes an incoming element Ack messages of elements produced must be processed before an Ack message for incoming element.
% \end{itemize}

% Ordering of messages per sender-receiver pair given to us by Akka framework fulfils these requirements.

\subsection{Single node \tracker\ implementation}
The naive version of the \tracker\ agent can be implemented as a single node agent. In this case, the logic directly follows the Algorithm~\ref{tracker_algo}. Though, due to the commutative nature of XOR operation, we are able to optimize \tracker\ incoming traffic by aggregating ack messages locally on worker nodes before sending them to the \tracker\ agent. For each worker node in the system, we introduce a \textbf{Local \tracker} component. It serves as a mediator between the node and the \tracker, buffering the outgoing ack and \textit{heartbeat} messages and flushing them periodically. The flushing window is the parameter that allows us to balance between the system latency and the service traffic. The optimal value of this parameter is defined by the execution graph topology and timing of particular operations.

\tracker\ use the latest \textit{heartbeat} message for each source and aggregates ack messages within the same \textit{global time} window to a single ack message via XOR product. On a flush, Local \tracker\ sends these messages in an ordered batch: ack messages come in order of associated \textit{global time} and \textit{heartbeat} messages come after them.

\subsection{Distributed \tracker}

As \tracker\ agent accumulates all the service traffic from the entire system, it may become a bottleneck. To deal with this problem, we introduce a distributed version of the \tracker\ agent. The challenge here is to support the ability of the user-defined code to emit elements of \textit{global time} greater than the current. Otherwise, the problem becomes trivial as we can shard the \tracker\ agent by the \textit{global time}, and all \tracker\ chains will use the same shard along their path and the completion of certain \textit{global time} is permanent. In this case, we can send \textit{min time update} based on information from a particular shard.

If this is not the case and the user is allowed to spawn items with the time greater than the time of the input element, it is possible that already nullified \textit{global time} will become active again. In this case, we need to take into account all \tracker\ shards to send the \textit{min time update} event.

We employ the vector clock algorithm to resolve this issue. Each worker machine either periodically sends its system time to all \tracker\ shards. The vector of observed worker times accompanies all \tracker\ notification events. The \tracker\ table is built on the \textit{min time update} event receivers side. Each row in this table is associated with the vector of worker times. All conditions in the list for accepting \textit{min time update} now check that the associated time vector is not less than the vector of compared time. For example, we need to check that all accumulators of the same segment become zero \textit{and} their vector is component-wise not greater than the current one.

The vector clock introduction increases the service traffic but allows to eliminate bottleneck from the system. The service traffic complexity remains the same, but the $O$ factor increases. In the experimental section, we will study how big is this increase.

% \subsection{Operation-level tracking}

% Our tracking mechanism can be made granular, tracking different parts of pipeline in case of directed acyclic graphs. For this we enrich Global Times with a pipeline identifier and change \tracker\ to track each pipeline part checksums in a separate buffer and limit minimal time of a pipeline part with minimal times of pipeline parts incoming into it. These changes make it possible for \tracker\ to emit Minimal Time Update messages for pipeline parts.
