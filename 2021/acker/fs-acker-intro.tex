\label {fs-acker-intro}

State-of-the-art distributed stream processing engines (SPEs) such as Flink~\cite{carbone2015apache}, Heron~\cite{Kulkarni:2015:THS:2723372.2742788}, or MillWheel~\cite{Akidau:2013:MFS:2536222.2536229} aim at handling potentially unbounded sequences of data elements. These systems receive input elements one-by-one, process them, update the internal in-memory state, and eventually release results. 

However, working with infinite data sequences has at least three difficulties. First, resources are limited, so the SPEs should maintain mechanisms to control their consumption~\cite{Tucker:2003:EPS:776752.776780}. Second, aggregations over unbounded sequences will never finish, so SPEs should provide some preliminary results~\cite{Begoli:2019:OSR:3299869.3314040}. Third, reprocessing of the whole data in case of failures is often impossible~\cite{Wang:2019:LSF:3341301.3359653}, and SPEs should support efficient recovery techniques.  

Unlimited streams are often considered as a mixture of limited {\em substreams} to deal with these difficulties. Substream is a part of the stream such that all its elements satisfy some predicate. {\em Substreams management problem} is to track all existing substreams and to provide a {\em signal}\footnote{We assume that data producers can provide such signals at first.} to all computational processes of an SPE when a substream ends, i.e., when there will be no more elements satisfying the predicate.

Let us consider several real-world scenarios that require substream management. Each of them handles a specific substream and requires particular signal properties.
\begin{itemize}
    \item {\bf State pruning}. SPEs can maintain an in-memory state with no upper bound in size and, so, run out of memory. To avoid this, SPEs can prune a state that corresponds to a substream when it ends. Note that this problem does not require any specific signal properties, but high latency between the substream termination and signal receiving reduces the efficiency of the technique.  
    \item {\bf Time windowed aggregations}. One way to provide preliminary results is to aggregate elements within event generation time windows. This feature is widely applied in online analytics~\cite{traub2018scotty}. The time window can be considered as a substream: to release output, an SPE needs a guarantee that all data within a time window are received. Some special scenarios, e.g., deterministic windowed join, require an order of signals to be synchronized with the order of input elements (signals from data producers)~\cite{najdataei2019stretch, gulisano2016scalejoin}.
    \item {\bf State snapshotting}. Epoch-based state snapshotting is a popular recovery technique applied in Flink~\cite{Carbone:2017:SMA:3137765.3137777}, Storm~\cite{Toshniwal:2014:STO:2588555.2595641}, Samza~\cite{Noghabi:2017:SSS:3137765.3137770}, IBM Streams~\cite{jacques2016consistent}. Within this method, all input elements are divided into special substreams called {\em epochs}. An SPE takes a state snapshot when a regular epoch is {\em atomically} processed. In case of failures, SPE can consistently recover state from the snapshot~\cite{2015arXiv150608603C}. Due to the atomicity requirement, the signal that an epoch ends should be received before any elements from the next epoch. 
\end{itemize}

A popular substreams management method is punctuations framework~\cite{tucker2003exploiting}. The main idea behind the punctuations framework is to divide the stream into substreams by injection of particular elements that define the ``border'' of a substream. While the punctuations approach is robust and easy-to-implement, it has two limitations. First, it does not support cyclic dataflows in general~\cite{carbone2018scalable}. Second, it has high network traffic overhead so that punctuations can reduce the throughput of an SPE for small substreams~\cite{Li:2008:OPN:1453856.1453890}. 

As we can see, substreams management problem appears in many practical scenarios. Moreover, the features of some substreams impose requirements on the substream end signals. In this work, we formalize the substream management problem and its properties to compare the capabilities of various techniques. We introduce a new substream management technique that supports all features required by practical scenarios and provides the lowest possible network overhead on regular processing. Our main contributions are listed below:


% State-of-the-art distributed stream processing systems such as Flink~\cite{Carbone:2017:SMA:3137765.3137777}, Heron~\cite{Kulkarni:2015:THS:2723372.2742788}, or MillWheel~\cite{Akidau:2013:MFS:2536222.2536229} are able to execute complex dataflows consisted of multiple operators that can be partitioned among workers. Each operator may execute almost arbitrary user-defined code that transforms elements into other ones or filters them out. After multiple transformations, it may not be clear which ingested by a system input element spawned an output. 

% To satisfy {\em consistency} and {\em fault tolerance} requirements, modern streaming engines support {\em dependency tracking} between input and output elements. Tracking mechanisms usually provide notifications that some set of ingested elements has already been transformed into outputs by the whole dataflow or its part. Such notifications are required for a plenty of problems: consistent {\bf state snapshotting}~\cite{Akidau:2013:MFS:2536222.2536229, 2015arXiv150608603C} to provide for correct failure-recovery, {\bf transactional processing} to ensure {\em delivery guarantees}~\cite{thepaper, Carbone:2017:SMA:3137765.3137777}, {\bf data producer cleanup}~\cite{Noghabi:2017:SSS:3137765.3137770} to support recovery while persistently storing only a part of input records, and so on. 

% Although most of the mentioned problems have been extensively studied for databases~\cite{DBLP:books/mk/WeikumV2002}, classical databases do not commonly face the problem of matching input and output because they mostly work under less strict latency requirements and persistently save information about all applied transformations. For instance, transactional processing methods employed in databases cannot be used as-is in distributed streaming systems without an adaptation of some dependency tracking technique~\cite{2015arXiv150608603C}.

% Most streaming systems apply one of the following approaches for dependency tracking: {\em micro-batching} and {\em markers}. In micro-batching, the output element may be originated only by an input one from the same micro-batch. Therefore, the completeness of a micro-batch indicates that all input elements within this batch are transformed into output elements. Markers approach bases on an injection of special input elements into a dataflow. These elements are broadcasted to each partition of the next operator and play the role of separators between ordinary records. Receiving such element from all partitions indicates that all upstream operators have entirely processed a particular set of input elements. 

% Both micro-batching and marker approaches have limitations and can induce high overhead on regular processing. Micro-batching has well-known issues with latency-conscious dataflows~\cite{S7530084}. It is hard to track individual records due to the ineffectiveness of very small micro-batches~\cite{Zaharia:2012:DSE:2342763.2342773}. The application of marker-based methods is limited for cyclic dataflows~\cite{Carbone:2017:SMA:3137765.3137777}. Besides, as we show further, markers may induce significant overhead on throughput due to a huge amount of extra network traffic.

% In this work, we present \tracker , a dependency tracking technique that provides for individual elements monitoring, while inducing a small overhead on regular processing. On the one hand, \tracker\ is suitable for a precise element-at-time streaming model without the need of micro-batching. On the other hand, it supports cyclic dataflows and requires a small amount of service traffic. \tracker\ can also monitor streaming elements within parts of dataflow as well as marker-based techniques. \tracker\ is deployed as an external agent that can scale out to sustain a high rate of input records. 

% This paper complements preliminary publications~\cite{we2018beyondmr, we2018adbis, thepaper}, which describe a stream processing system that uses \tracker\ as a component. In this paper, we detail a formal concept of \tracker , propose its distributed implementation, and evaluate the~\tracker\ performance in a more narrowly focused way. Our main contributions are:
% \begin{itemize}
%     \item Design of general formal concepts for a dependency tracking mechanism
%     \item Transformation of these concepts into the~\tracker\ using ideas from Apache Storm {\em \acker}~\cite{Toshniwal:2014:STO:2588555.2595641}
%     \item Demonstration of the \tracker\ practical feasibility and performance insights
% \end{itemize}

% The rest of the paper is organized as follows: Section~\ref{fs-acker-motivation} gives an overview of existing dependency tracking solutions and practical tasks that require a tracking mechanism. In Section~\ref{fs-acker-design}, we design formal concepts for dependency tracking methods and turn these concepts into the \tracker\ mechanism. Section~\ref{fs-acker-impl} summarizes the implementation of \tracker\ for both centralized and distributed setups with optimizations that can reduce the amount of extra traffic. In Section~\ref{fs-acker-experiments}, we show that the proposed technique is scalable, and can outperform alternatives employed in state-of-the-art stream processing engines. Finally, we discuss our conclusions in Section~\ref{fs-acker-conclusion}.