 %%% fs-state-related - Related work

\label {fs-related-seciton}

Techniques for providing exactly-once~\cite{Carbone:2017:SMA:3137765.3137777, Akidau:2013:MFS:2536222.2536229, Zaharia:2012:DSE:2342763.2342773} are discussed   in details in sections~\ref{fs-intro-seciton} and~\ref{fs-eo-impl}. Many prior works in the field of stream processing do not consider exactly-once maintenance. 
For instance, Aurora~\cite{Abadi:2003:ANM:950481.950485} and Borealis~\cite{abadi2005design} do not provide any guarantees on data at all. Some other systems provide only partial consistency. Apache Storm~\cite{apache:storm} supports the message tracking mechanism that prevents the loss of data. 
However, exactly-once semantics is not provided, because duplicates are still possible. Twitter Heron, that was presented as the next generation of Apache Storm~\cite{Kulkarni:2015:THS:2723372.2742788}, does not provide for exactly-once as well. 
Samza~\cite{Noghabi:2017:SSS:3137765.3137770} also implements fairly similar to Storm model and has the same consistency guarantees.

Prior works on stream processing formalization concentrate on operations specifications rather than delivery guarantees. The logical foundation for specifying streaming computations is discussed in~\cite{alur2018interfaces}. Declarative algebraic notations for the streaming queries are introduced in~\cite{halle2014formalization}. Another direction in streaming formalization is designing frameworks to define operations semantics~\cite{beck2018lars}.

A comprehensive analysis of different approaches to failure recovery mechanisms in stream processing is provided in~\cite{Wang:2019:LSF:3341301.3359653}.  The authors observe that in order to implement consistency guarantees, executing systems have to choose between checkpoints and lineage. The checkpoints tend to add low runtime overhead during the normal execution, while lineage usually results in faster failure recovery. In terms of the above classification, our prototype belongs to the first group, as it relies on the total ordering of input items and re-plays all items that weren't delivered before failure. However, in this work, we demonstrated that a non-deterministic system needs to persistently save information about an element resulted from the non-commutative operation before delivery, no matter which failure recovery mechanism is used. This fact revealed that checkpoints also induce latency overhead in non-deterministic systems. This overhead can be significantly reduced within a deterministic streaming engine. Hence, a particular method to save and recover a system state should be chosen based on specific user requirements. Our motivation behind the checkpoint-based method is an observation that failures are usually not so frequent in practice~\cite{Akidau:2013:MFS:2536222.2536229}.

The authors of \cite{Wang:2019:LSF:3341301.3359653} also describe an approach that allows non-deterministic processing during normal execution but reproduces exactly the same lineage during recovery.  It results in effectively deterministic computation. In contrast with our work, the lineage is produced dynamically during the execution. This approach still results in significant computational overhead, but the lineage may be saved asynchronously and thus produces only a minor impact on the latency. An implementation of a lineage-based recovery technique based on a deterministic stream processing engine is one of the directions of our future work.
