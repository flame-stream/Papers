\label {fs-short-model}

Assume that streaming data is partitioned among multiple independent computational units. Data partitioning is defined by business logic and we cannot affect it. In this case, each computational unit receives only a sample of all data stream elements. We consider two approaches for testing that data fits a given probability distribution:

\begin{itemize}
    \item Merge all data to a single computational node and apply the test on it.
    \item Test data independently on each unit.
\end{itemize}

As we show further, the first approach limits throughput and causes extra communication cost. In our work, we concentrate on independent testing. It has minimal performance overhead because data is tested on a node that it has already arrived at. The following questions and challenges arise regarding the implementation of this method:

\begin{itemize}
    \item Despite the fact that each computational unit processes only its own sample, these samples still can be infinite due to streaming nature of data. Therefore, there is a need to make tests without storing the whole arrived data.
    \item It is unclear how independent testing influences the time of detection of unexpected distribution. There is a need to investigate the limits of applicability of the proposed method.
    \item Each computational node can process only a limited subset of all possible values. For example, each node can receive only values with defined values of balancing hash function~\cite{carbone2015apache}. It is important to find out how this fact can influence the results for different types of probability distributions.
    \item Test results from a single computational node may be inaccurate due to the issues mentioned above. To overcome this issue, protocols for making decisions based on the outcome of each independent unit are required.
    % \item Samples can be distributed slightly different due to unbalanced partitioning. Hence, distribution parameters must be computed independently on each node.
    \item State-of-the-art stream processing systems~\cite{Carbone:2017:SMA:3137765.3137777, apache:storm, Zaharia:2012:DSE:2342763.2342773} provide API for working with {\em logical} partitions, but do not have standard tools for working with data arrived at computational nodes. There is a need to extend standard APIs to apply the proposed approach on top of these systems.
\end{itemize}