\label {fs-short-intro}

Classification of large text streams is hard, but important task for researchers and practitioners. It has a wide range of applications including detection of emerging news and current user interests, suspicious traffic analysis, spam detection, etc. Popular open-source libraries like sklearn~\cite{sklearn_api} and NLTK~\cite{bird2009natural} provide a rich set of tools, but they mostly aim at handling static datasets. The lack of scalability across multiple computational units is another restriction of these solutions. There are plenty of works which adapt batch processing systems for text classification~\cite{semberecki2016distributed, svyatkovskiy2016large, baltas2016apache, Nodarakis2016LargeSS}. Their advantages are fault tolerance, high throughput, and scalability. On the other hand, these systems do not provide low latency that is a strong requirement for most streaming applications.

An immediate idea is to employ a distributed stream processing engine such as Flink~\cite{Carbone:2017:SMA:3137765.3137777} or Storm~\cite{apache:storm}. However, unlike batch engines, stream processing systems have several distinctive features: 

\begin{itemize}
    \item In a general case, failure and recovery is not transparent for a user. The guarantees on data in case of failures are defined in terms of delivery guarantees: {\em at least once} and {\em exactly once}. The choice of a guarantee may affect the correctness of a text classification pipeline.
    \item Most of streaming systems are inherently non-deterministic. It means that different runs on the same data may produce different results. This property can influence the classification process as well.
\end{itemize}

In this work, we investigate the applicability of state-of-the-art stream processing systems to the text classification and demonstrate the challenges that a developer can experience. We also propose a data flow on top of~\FlameStream\ processing engine~\cite{we2018beyondmr, we2018adbis} that mitigates the highlighted issues. In particular, the proposed distributed data flow behaves like it is executed on a single machine that is convenient for end-user. It is demonstrated that the proposed solution has linear throughput scalability with low latency (under 100 ms for 99th percentile) while providing reasonable classifier accuracy on a real-world corpus of news articles.

The rest of the paper is structured as follows: the problem of text classification using stream processing engines and the proposed data flow are discussed in section~\ref{fs-framework}, the performance of the data flow and machine learning model is discussed in section~\ref{fs-experiments}, prior works on the topic are mentioned in section~\ref{fs-related}.
