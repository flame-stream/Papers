\label {fs-short-intro}

Classification of large text streams is hard, but important task for researchers and practitioners. It has a wide range of applications including detection of emerging news and current user interests, suspicious traffic analysis, spam filtering, etc. Popular open-source libraries like sklearn~\cite{sklearn_api} and NLTK~\cite{bird2009natural} provide a rich set of tools, but they mostly aim at handling static datasets. The lack of scalability across multiple computational units is another limitation of these solutions. There are plenty of works which adapt batch processing systems for text classification~\cite{semberecki2016distributed, svyatkovskiy2016large, baltas2016apache}. Their advantages are fault tolerance, high throughput, and scalability. On the other hand, these systems do not provide low latency that is a strong requirement for most streaming applications.

An immediate idea is to employ a distributed stream processing engine such as Flink~\cite{Carbone:2017:SMA:3137765.3137777} or Storm~\cite{apache:storm}. However, unlike batch engines, stream processing systems have several peculiarities: 

\begin{itemize}
    \item In a general case, failure and recovery are not transparent for a user. The guarantees on data in case of failures are defined in terms of delivery guarantees: {\em at least once} and {\em exactly once}. The choice of a guarantee may affect the correctness of text classification.
    \item Most of streaming systems are inherently non-deterministic. It means that different runs on the same data may produce different results. This feature can influence the classification process as well.
\end{itemize}

In this work, we investigate the applicability of state-of-the-art stream processing systems to the text classification and demonstrate the challenges that a developer can experience. We adapt text classification data flow that is typical for batch processing systems for state-of-the-art stream processing engine Apache Flink~\cite{Carbone:2017:SMA:3137765.3137777}. We show that failures within {\em at least once} guarantee may significantly shift the distribution of classification results. It is also indicated that races due to asynchronous channels in the data flow lead to non-reproducible classification results. We demonstrate that straightforward solutions to the revealed issues may lead to performance overhead. More sophisticated approaches to solve the problems are touched upon.

The rest of the paper is structured as follows: the problem of text classification using stream processing engines and the typical data flow are discussed in section~\ref{fs-framework}, section~\ref{fs-discussion} contains the evaluation of the data flow on top of state-of-the-art stream processing system, approaches to get around the revealed issues are introduced in section~\ref{fs-solution}, prior works on the topic are mentioned in section~\ref{fs-related}, we discuss the results and our plans in~\ref{fs-conclusion}.