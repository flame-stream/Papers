\label {fs-short-intro}

Text analysis and, in particular, text classification is an emerging field of study. It has a wide range of applications in information extraction, text retrieval, question-answering, etc~\cite{tampakas2005}. Machine learning methods are considered as a state-of-the-art in this field. Linear models such as SVM or logistic regression together with TF-IDF vectors as a feature set commonly provide a reasonable quality~\cite{???}. These techniques are implemented in popular open-source libraries like sklearn~\cite{sklearn_api} and NLTK~\cite{bird2009natural}. The lack of scalability across multiple computational units is the main restriction of such solutions.

In case of large but static datasets, it is possible to adopt batch processing systems for text classification. An example of this approach is demonstrated in~\cite{semberecki2016distributed}. Its advantages are high throughput and practically unlimited scalability.

On the other hand, there are tasks, where data is coming as a stream. Streaming news or user logs classification are the examples of such tasks. In this case, there is a need for a low latency between obtaining a text and answer delivery. Data can also be shifted to a different topic depending on the current events or user interests. Existing works on streaming data classification aim at handling the streaming nature of data, rather than take scalability into account~\cite{zhang2008one}.

In the transition to the distributed streaming computational model, the following challenges arise:

\textbf{Distributed TF-IDF computing.} Text features must be computed in a distributed manner, otherwise, this part of the pipeline would be a bottleneck.

\textbf{Partial fitting.} Our model is able to adapt to new labels of documents during streaming. To achieve this, additional fitting is considered fast enough, so the model does not lose it's perfomance.

\textbf{Model updating.} After the additional training, new model should be delivered to every processing unit in the pipeline, so the size of the model should be reasonably small in order to faster updating the pipeline.

\textbf{Handling the concept drift.} Streaming nature of data implies high data velocity. For instance, words can have different meanings depending on user interest or recent events. Such behavior can shift the labels of the input texts. In order to overcome this problem we use a sliding window for computing IDF.

In this work we want to introduce computational pipeline and machine learning model as a solution for the scalable distributed streaming text classification. TF-IDF features are computed using sharding technique [?]. As a classifier model we use logistic regression with l1 and l2 regularizations. The model is pretrained on the initial dataset and then is able to continue to train in real-time on the streaming data. Besides our approach, we describing what problems we had and how we managed to solve them and providing our experiments based on FlameStream platform [].
