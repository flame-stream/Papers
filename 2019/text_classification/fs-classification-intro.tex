\label {fs-short-intro}

% Something interesting is here~\cite{Carbone:2017:SMA:3137765.3137777}.

% 1) Задача классификации текстов - это важно
% 2) Если данных мало - то все ок (sklearn, nltk)
% 3) Если данных много, но датасет статический - то мап редьюс. И, кстати, это уже сделано
% 4) А если не статический, то надо делать на потоке.
% 5) Кто-то делал на потоке (ссылки), но не распределенно - упираемся в масштабируемость
% 6) В этой статье мы предлагаем пайплайн вычислений и модель машинного обучения для эффективной рапспределенной классификации потока текстов:
% - Шардированное вычисление TF-IDF фичей 
% - Real-time дообучаем логистическую регрессию
% 7) Помимо подхода, мы описываем сложности и проводим эксперименты на базе FlameStream (ссылка)

Text analysis and, in particular, text classification is an emerging field of study. Nowadays, text classification is successfully applied in information extraction, text retrieval, question-answering, etc~\cite{tampakas2005}.
There are typical approaches for solving this problem. Machine learning methods are considered as a baseline in this field. As a model the linear Support Vector Machines and logistic regression are used as the common candidates. For vectorizing the data TF-IDF [] is used as features, where TF is known as term-frequency and IDF as inverse document frequency. When the data is limited in size for processing it on the one machine the libraries, where such models is implemented, are used. For instance, sklearn [] and NLTK for natural language processing.

Howerer, in the case, the amounts of data is increasing such as it cannot be processed by only one machine, this methods are not enough anymore. With distributed processing Map Reduce as a common technique for big data can be used. This method was used [] for text classification on Apache Spark Platform. The system is able to work on huge amounts of data and applicable for tasks, where size of the dataset is remaining static.

On the contrary, there are a few tasks exists, where data has a streaming nature, which implies potential infinite amounts of data and the concept drift, where data can shifts to a different topic depending on the users interests, might take place. In addition, in such systems there is a need for low latency between obtaining a document and computing the answer. Сlassification of streaming news provides a good example of such task. Solutions for similar problems were considered by []. This proposed approaches due to the nature of data are able to work with non-static datasets, howerer, in this solutions scalability is not considered, thus, they can be used effectively only on the one machine.

In the transition to the distributed streaming computing model, the following challanges are arise:

\textbf{Distributed TF-IDF computing.} Features of the documents are proposed to compute in a distributed manner, otherwise, this part of the pipeline is able to produce a bottleneck, which removes property of scalability.

\textbf{Handling the concept drift.} Users may change their interests from time to time, so it shifts the labels of the streaming documents. In order to overcome this problem we managed to use a sliding window for computing document features.

\textbf{Additional training.} Our model is able to adapt to new labels of documents during streaming. To achieve this, additional fitting is considered fast enough, so the model does not lose it's perfomance.

\textbf{Model updating.} After the additional training, new model should be delivered to every processing unit in the pipeline, so the size of the model should be reasonably small in order to faster updating the pipeline.

In this work we want to introduce computational pipeline and machine learning model as a solution for the scalable distributed streaming text classification. TF-IDF features are computed using sharding technique [?]. As a classifier model we use logistic regression with l1 and l2 regularizations. The model is pretrained on the initial dataset and then is able to continue to train in real-time on the streaming data. Besides our approach, we describing what problems we had and how we managed to solve them and providing our experiments based on FlameStream platform [].
