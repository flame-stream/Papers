\label {fs-short-intro}

Classification of large text streams is hard, but important task for researchers and practitioners. It has a wide range of applications including detection of emerging news and current user interests, suspicious traffic analysis, spam detection, etc. Popular open-source libraries like sklearn~\cite{sklearn_api} and NLTK~\cite{bird2009natural} provide a rich set of tools, but they mostly aim at handling static datasets. The lack of scalability across multiple computational units is another limitation of these solutions. There are plenty of works which adapt batch processing systems for text classification~\cite{semberecki2016distributed, svyatkovskiy2016large, baltas2016apache}. Their advantages are fault tolerance, high throughput, and scalability. On the other hand, these systems do not provide low latency that is a strong requirement for most streaming applications.

An immediate idea is to employ a distributed stream processing engine such as Flink~\cite{Carbone:2017:SMA:3137765.3137777} or Storm~\cite{apache:storm}. However, unlike batch engines, stream processing systems have several peculiarities: 

\begin{itemize}
    \item In a general case, failure and recovery are not transparent for a user. The guarantees on data in case of failures are defined in terms of delivery guarantees: {\em at least once} and {\em exactly once}. The choice of a guarantee may affect the correctness of text classification.
    \item Most of streaming systems are inherently non-deterministic. It means that different runs on the same data may produce different results. This feature can influence the classification process as well.
\end{itemize}

In this work, we investigate the applicability of state-of-the-art stream processing systems to the text classification and demonstrate the challenges that a developer can experience. We show that failures within {\em at least once} guarantee may significantly shift the distribution of classification results. It is also indicated that a non-deterministic pipeline leads to non-reproducible classification results. Another issue that we discuss is embedding of offline learning algorithms into a data flow: there is a trade-off between reproducibility and latency spikes in this case.  

In order to mitigate the highlighted issues, we introduce a data flow on top of~\FlameStream\ processing engine~\cite{we2018beyondmr, we2018adbis}. The proposed distributed data flow behaves like it is executed on a single machine and provides unbiased by failures results. FTRL proximal algorithm~\cite{mcmahan2013ad} is adopted for online learning within the data flow and provides reasonable classifier accuracy on a real-world corpus of news articles. It is demonstrated that the solution has linear throughput scalability with low latency (under 100 ms for 99th percentile).

The rest of the paper is structured as follows: the problem of text classification using stream processing engines and the typical data flow are discussed in section~\ref{fs-framework}, section~\ref{fs-discussion} contains the evaluation of the data flow on top of state-of-the-art stream processing system, enhancements of a typical data flow is introduced in section~\ref{fs-solution}, performance evaluation of the proposed solution is discussed in section~\ref{fs-experiments}, prior works on the topic are mentioned in section~\ref{fs-related}.