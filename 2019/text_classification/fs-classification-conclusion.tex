\label {fs-conclusion}

In this work, we investigated the suitability of distributed stream processing engines to the problem of text streams classification. We demonstrated that distributed text stream classification has several peculiarities:

\begin{itemize}
    \item Races in a physical data flow may lead to partially reproducible results: labels provided by a classifier may vary from run to run on the same test data.
    \item Changes in classifier outcome for individual elements due to races does not imply differences in classifier accuracy. 
    \item Failures within {\em at-least-once} delivery guarantee can cause a biased distribution of classification results.
\end{itemize}

It was shown that a straightforward approach to the mentioned issues has a significant performance overhead. A potential solution to this problem is to apply speculative optimistic approaches to enforce total order of processing that can lead to both determinism and exactly-once with low performance overhead. 

A machine learning model needs to be updated on-the-fly to capture rapid changes of the stream. As future work, we plan to implement a text classification framework that satisfies the following requirements:

\begin{itemize}
    \item Fault-tolerant with low latency: node failures do not affect the ultimate result distribution.
    \item Reproducible: if input elements are stored in persistent storage, the same predictions are obtained on each new run.
    \item Concept drift conscious: changes in streaming data must be reflected in a machine learning model.  
\end{itemize}