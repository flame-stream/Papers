\label {fs-conclusion}

In this work, we investigated the suitability of distributed stream processing engines to the problem of text streams classification. We demonstrated that distributed text stream classification has several peculiarities:

\begin{itemize}
    \item Races in a physical data flow may lead to partially reproducible results: labels provided by a classifier may vary from run to run on the same test data.
    \item Irreproducibility of the classifier outcome in terms of individual elements does not imply the irreproducibility in terms of classifier accuracy. 
    \item Failures within {\em at least once} delivery guarantee can cause a biased distribution of classification results.
\end{itemize}

It was shown that a straightforward approach to the mentioned issues implies significant performance overhead. A potential solution to this problem is to apply speculative optimistic approaches to enforce total order of processing that can lead to both determinism and exactly once with low performance overhead. 

A machine learning model needs to be updated on-the-fly to capture rapid changes of the stream. As future work, we plan to implement a text classification framework that satisfies the following requirements:

\begin{itemize}
    \item Unbiased by distributed environment: node failures or races do not affect the ultimate result distribution.
    \item Reproducible: if input elements are stored in persistent storage, the same predictions are obtained on each new run.
    \item Concept drift conscious: changes in streaming data must be reflected in a machine learning model.  
\end{itemize}