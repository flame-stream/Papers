\label {fs-short-conclusion}

In this work, we investigated the suitability of distributed stream processing engines to the problem of text streams classification. We demonstrated that there are several pitfalls with a straightforward approach. If we claim that output must depend on input only, but not on possible failures or processing environment features, the following limitations arise:

\begin{itemize}
    \item Exactly once becomes a strong requirement.
    \item Embedding of time-consuming train process in the prediction pipeline leads to significant latency spikes.
\end{itemize}

To mitigate the highlighted issues, we proposed a text classification data flow on top of~\FlameStream\ processing system that is explicitly divided into {\em predicting} and {\em training} pipelines. The predictions obtained through the proposed data flow are:

\begin{itemize}
    \item Unbiased by distributed environment: node failures or races do not affect the ultimate result distribution.
    \item Reproducible: if input elements are stored in persistent storage, the same predictions are obtained on each new run.
\end{itemize}

We demonstrated that the proposed solution provides for low latency and linear scalability together with reasonable classification accuracy. We also realized that the way how the training and prediction pipelines can be efficiently combined together is the usage of online learning algorithms. We leave the investigation of this task as future work.