\label{fs-acker-preliminaries}

First, in this section, we formalize a stream processing engine based on Chandy-Lamport distributed system definition. Then we define the substream management problem based on the notions from the proposed model. Finally, we describe a state-of-the-art substream management technique called punctuations in terms of our framework.

\begin{table}[!b]
    \caption{Notations used throughout the paper}
    \footnotesize
    \begin{tabular}{l|p{5cm}}
        \hline
        $p$ & Process (node in a physical execution graph) \\ 
        \hline
        $I_p$, $O_p$ & input and output channels of a process $p$ \\ 
        \hline
        $func_p(U, M)$ & User-defined operator run by process $p$. It receives current operator state $U$ and an incoming message $M$ \\ 
        \hline
        $\Pi$ & The set of all processes  \\
        \hline
        $K$ & Number of substreams (can be unlimited if substreams are regularly created) \\
        \hline
        $c$ & A network channel between processes  \\
        \hline
        $\mathcal{E}$ & The set of all network channels  \\
        \hline
        $s_p = U_p \cup B_p$ & State of the process $p$ consists of a mailbox $B_p$ and a state $U_p$ of $func_p$ \\
        \hline
        $mbc_{p}$ & Mailbox controller of a process $p$ \\
        \hline
        $e_{p}$ & Event of a process $p$ \\
        \hline
        $Pred(e)$ & Propositional formula defined on events \\
        \hline
        $pred(M)$ & Propositional formula defined on messages\\
        \hline
        $t(M)$ & Coarse time label \\
    \end{tabular}
    \label{notations}
\end{table}

\subsection{Stream processing model}
\label{fs-acker-processing-model}

\subsubsection{SPE model}
\label{fs-acker-spe-model}

Typically, distributed stream processing engines are shared-nothing runtimes that continuously ingest input elements, transform them according to a logical dataflow graph, and deliver output elements. The logical dataflow graph consists of user-defined operators. Operators are functions of a single input data element that produce output data elements. Operators can be stateless or stateful: output elements may depend on the current state. An SPE maps a logical graph to a physical (distributed) graph on deployment. Commonly, a single logical operator can be deployed on multiple computational nodes. Further, we denote physical instances of logical operators as {\em processes}.

We can describe a deployed physical graph as a distributed system in Chandy-Lamport model~\cite{Chandy:1985:DSD:214451.214456, carbone2018scalable}. In this model, the authors introduce \textit{events} that allow observing the entire system's state. This approach allows defining system-wide guarantees: in the original paper, authors used it to introduce the notion of {\em consistent state}. We use this approach for the definition of a substream management problem.

Following the notation from~\cite{Chandy:1985:DSD:214451.214456, carbone2018scalable}, one can observe a distributed system with events. 

\begin{definition}[Event]
An event is a tuple of 5 elements $e = (p, s, s', c, M)$, where $p$ is one of the deployed processes, $s$ and $s'$ are the state of the process before and after processing, $c$ is one of network FIFO channels that connect processes, and $M$ is a message generated during processing.
\end{definition}

The generated event $M$ comes to a channel state $C$ until the destination process receives it. Processes and channels form a physical graph of the system $G=\{\Pi,\mathcal{E}\}$. We denote all input channels as $I_p$ and output channels as $O_p$.

In a stream processing engine, we need to specify a process $p$ to reflect the nature of SPE. 

\begin{definition}[Process]
A process in an SPE is an actor consisting of {\em business logic handler} (BLH) and {\em mailbox controller} (MBC). The first block encapsulates a user-defined operator. The user-defined operator does not directly communicate with other processes in the system. Instead, it receives and generates {\em messages} -- data elements tagged by their source and destination. The mailbox controller handles further delivery of these messages along the communication channels and preserves the order of message generation.
\end{definition}

Figure~\ref{fig:spe_process} illustrates the scheme of a process. This system layout is not new and is widely used in practice (Akka, YDB, Millwheel, etc.).

\begin{figure}[t]
  \centering
  \includegraphics[width=0.3\textwidth]{pics/process-scheme.pdf}
  \caption{Structure of the SPE process}
  \label{fig:spe_process}
\end{figure}

\subsubsection{Stream processing events}

When a process receives a message, the mailbox controller puts it into a particular segment of the process state ({\em mailbox} $B_p$). The business logic handler gets a message provided by MBC and triggers a user-defined operator. The user-defined operator processes the data element that the message contains and generates an arbitrary number of outgoing messages. BLH puts generated messages back in a mailbox. MBC sends outgoing messages along communication channels to destination processes. All mailbox controller operations respect the order of messages in the mailbox. If a user-defined operator has a state $U_p$, the joined process state will consist of the mailbox and this state $s=U_p \cup B_p$. In the Chandy-Lamport paradigm, this algorithm produces the following events within a process:
\begin{itemize}
    \item Communication events: $\langle recv, p, M\rangle$, $\langle send, p, M \rangle$ -- these events are handled by mailbox controller
    \item Processing of an incoming message $\langle proc, p, M, M' \rangle$
\end{itemize}

Let us translate these events into 5-tuple language. Communication events move a message between the communication channel and the mailbox section of the state:

\begin{multline}
\langle recv, p, M\rangle = \\ (p, s_p, s'_p = U_p \cup \left(B_p \cup \{M\}\right), c_{qp}, M)
\end{multline}

\begin{multline}
\langle send, p, M \rangle = \\ (p, s_p, s'_p = U_p \cup \left(B_p\setminus\{M\}\right), c_{p, dst(M)}, M)
\end{multline}

This function translates a destination of an element from logical dataflow graph nodes to physical communication channels between processes. Note that we need to be able to get a destination process directly from the message $dst(M)$. A practical case of this abstraction is a sharding scheme for some key: a user-defined procedure emits an event for some key, and a system is responsible for finding a proper physical channel to deliver this message.

Incoming message processing does not influence the communication channels and only ingest results of a message processing $(U', M') = func_p(U, M)$:
\begin{multline}
    \langle proc, p, M, M' \rangle = \\ (p, s_p, s'_p = U'_p \cup \left(B_p \setminus \{M\} \cup M' \right) , \emptyset, \emptyset)
\end{multline}

Note that in this case, $M'$ may contain multiple messages. Following the Chandy-Lamport model, we assume processes are single-threaded, so within the specific process $p$, all events are ordered by a local causal order relation $<_p$: $e^{0}_p,e^{1}_p,\ldots,e^{i}_p,\ldots$. Please note that each process has its own local causal order relation, so we do not assume any total order among events from different processes. This model is indeed practical, e.g., implemented in actor-based systems.

\subsection{Substream management events}
\label{fs-acker-substream-events}
\subsubsection{Substreams lifespan}

We want to get a substream's first and last element for each process. One can easily find the first one when it emerges, but verification that there will be no more events of a substream could be problematic. The strict substream termination guarantee consists of two parts: the source must promise that no more messages from the substream may emerge, and the system must ensure it contains no substream messages. The first task requires a contract with a particular data source and is thus out of scope for this paper, though it is discussed in relevant literature~\cite{awad2019adaptive}. Instead, we focus on the second task; this is challenging due to distributed nature of the system and the absence of a standard message lifetime limit. This difficulty increases with the introduction of cycles into dataflow. Crucially, processes are not isolated, and substream messages can move from one process to another. That is why we need to observe all in-flight messages in the system.

\begin{definition}[Substream]
All events in a system satisfying a propositional formula $Pred(e)$ form a substream.
\end{definition}

We have to use system events as they are ordered inside each process and can define a border of a substream. Sometimes it is more practical to induce this predicate to messages ($pred(M)$) involved in processing: $Pred(e) = (e = \langle proc, p, M, M'\rangle) \wedge pred(M)$.

This paper considers substreams with a limited lifespan within a process. We want to know when a substream starts and terminates: 

\begin{multline}
\forall p, \exists t_0^p, t_1^p: \exists e: e_{t_0^p} <_p e <_p e_{t_1^p}, Pred(e) \And \\ \forall e': e_{t_1^p} <_p e', \neg Pred(e') 
\end{multline}

We can boil this formula down: for each process $p$ in the system, there must be two event indices $t_0^p$ for substream start and $t_1^p$ for its termination, such that events satisfying $Pred$ must be between them. 

\begin{definition}[Substream management problem]
A substream management problem is to estimate a substream bound for each process. To indicate the bound of a substream for a process, we use a termination event or end-of-substream event:
\begin{multline}
  \langle eoss, p, Pred \rangle = (p, B_p, B_p\cup eoss(Pred), \emptyset, \emptyset)  
\end{multline}
\end{definition}

Some problems require additional properties of the termination events. For example, the state pruning problem does not require any particular properties, while for the state snapshotting problem, the substream management system should detect the exact substream bound. In the following sections, we formalize these properties. 

\subsubsection{Soft bound}

Many applications that apply substream management systems do not require any particular properties of termination events. In this case, we denote the guarantee provided by such events as {\em soft bound} because termination events indicate that the substream ended some time ago.

\begin{definition}[Soft bound]
Termination event (end-of-substream) $\langle eoss_{soft}, p, Pred\rangle$ satisfies a soft bound guarantee iff:

\begin{equation}
\forall e, e >_p \langle eoss_{soft}, p, Pred\rangle \Rightarrow \neg Pred(e)
\end{equation}
\end{definition}

Figure~\ref{general_guarantees} illustrates this notion. Terms $a,b,c,d...$ denote ordered processing events of a process $p$. The substream ends after event $c$. Note that there are several other events between the end-of-substream and $c$. If $\langle eoss_{soft}, p, Pred\rangle$ occurs, all subsequent elements do not satisfy the predicate, but it is not necessarily the exact substream ``border''.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.50\textwidth]{pics/general-guarantee.pdf}
  \caption{Substream management: soft bound}
  \label{general_guarantees}
\end{figure}

\subsubsection{Firm bound}

The guarantee that any new event will not satisfy the predicate is sufficient for many real-life problems, e.g., SPE can initiate process state pruning on such events. However, some problems require a {\em firm bound}: guarantee that the substream ends {\em exactly} after the termination event. 

For example, a commonly used snapshotting protocol~\cite{2015arXiv150608603C, jacques2016consistent} relies on an {\em epoch}. An epoch is a special substream that must be processed atomically. Therefore, the SPE requires the termination event for a given epoch to occur immediately after the last processing event belonging to that epoch. Otherwise, the snapshot can be inconsistent, capturing elements from multiple epochs. The end-of-substream event $\langle eoss_{firm}, p, Pred\rangle$ should satisfy a {\em firm bound } guarantee to support such scenarios.

\begin{definition}[Firm bound]
Termination event (end-of-substream) $\langle eoss_{firm}, p, Pred\rangle$ satisfies a firm bound guarantee iff:

\begin{multline}
\langle eoss_{firm}, p, Pred\rangle = \inf_{<_p} \langle eoss_{soft}, p, Pred\rangle
\end{multline}
\end{definition}

Unlike the soft bound, within the firm guarantee, the first element outside the substream $Pred$ must be ordered after the firm bound event in the process $p$. This position satisfies the first possible soft bound in the events ordering. Figure~\ref{strict_guarantees} illustrates the notion of the firm bound. As in the previous example, terms $a,b,c,d...$ denote ordered processing events of a process $p$. However, in this case, event $\langle eoss_{firm}, p, Pred\rangle$ occurs right after the substream terminates.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.50\textwidth]{pics/strict-guarantee.pdf}
  \caption{Substream management: firm bound}
  \label{strict_guarantees}
\end{figure}

\subsubsection{Consistent termination events order}
Some applications require synchronization between substream termination events and substreams' last elements processing. Among these applications are epoch-based snapshotting methods and techniques for enforcing deterministic processing~\cite{we2018adbis}. For example, snapshots for consecutive epochs can be inconsistent if termination events reordering occurs. Another example is deterministic join~\cite{gulisano2016scalejoin}, which also requires the synchronized order of termination events.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.50\textwidth]{pics/notifications-reordering.pdf}
  \caption{An example of termination events reordering}
  \label{notifications_reordering}
\end{figure}

Figure~\ref{notifications_reordering} illustrates termination events reordering in the case of the soft bound guarantee. Terms $a,b,c,d...$ denote ordered processing events of a process $p$. Although the substream containing events $a,b$ terminates earlier, the end-of-substream event for this substream occurs after the termination event for the substream containing events $d,e$. 

\begin{definition}[Consistent events order]
Let $e^{*}_1$ and $e^{*}_2$ be the last elements of substreams defined by predicates $Pred_1$ and $Pred_2$. Termination events $\langle eoss, p, Pred_1\rangle$ and $\langle eoss, p, Pred_2\rangle$ are {\em consistently ordered} iff:

\begin{equation}
e^{*}_1 >_p e^{*}_2 \Leftrightarrow \langle eoss, p, Pred_1\rangle >_p \langle eoss, p, Pred_2\rangle
\end{equation}
\end{definition}

\subsubsection{Optimal traffic overhead}

A vital performance property of a substream management system is the amount of extra network traffic. Let $|\Pi|$ be the number of processes, and $K$ be the number of substreams~\footnote{number of all created substreams, no matter if they exist concurrently or not}. 

\begin{lemma}
The network overhead induced by a substream management system cannot be lower than $O(K|\Pi|)$. 
\end{lemma}
\begin{proof}
Assume one-by-one substreams processing (e.g., epochs). When a substream management system detects the termination of a substream, each stateful process should be informed about this. Hence, each process must receive at least one network message (termination notification) for each substream.
\end{proof}

In this proof, we assume that each process should be informed about substream termination, while some processes may not require such notifications, for example, if they are stateless. This assumption is realistic because, as we mentioned in Section~\ref{fs-acker-spe-model}, logical operators are commonly deployed on each computational node, e.g., in state-of-the-art SPEs such as Flink~\cite{Carbone:2017:SMA:3137765.3137777}, Storm~\cite{apache:storm}, Samza~\cite{Noghabi:2017:SSS:3137765.3137770}. In this model, each process must receive the substream termination event because each process handles all logical operators.

\subsection{Punctuations framework}
\label{fs-acker-punctuations}

To justify the usefulness of our model described above in Section~\ref{fs-acker-substream-events}, we show how our model can describe the most widely used substream management framework called {\em pucntuations}. We also prove specific properties that are inherent to any implementation of the punctuation framework. 

\subsubsection{Framework overview}

The main idea behind the punctuation framework is to inject special data elements $\mathcal{P}^{pred}$ into the data stream one per substream. These elements, called punctuations, flow down the workflow as ordinary data elements. The injector promises that all elements after punctuations will not satisfy the predicate. Hence, the punctuation itself defines the ``border'' of a substream.

Figure~\ref{punctuations_scheme} illustrates the punctuations framework. Punctuations are delimiters between the substream elements and all other items. Green elements indicate elements that belong to some substream, while red elements do not.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.40\textwidth]{pics/punctuations-scheme.pdf}
  \caption{Punctuations handling by a single process}
  \label{punctuations_scheme}
\end{figure}

Processes within SPE do not apply user-defined operators to punctuations. Instead, each process $p$ propagates punctuation messages $\mathcal{P}_{pq}^{pred}$ to all outgoing channels $c_{pq} \in O_p$  when it receives corresponding punctuations from all input channels $I_p$.

\subsubsection{Substream termination events}

\begin{lemma}
Generating an event by the following rule ensures the soft bound of a substream $pred$:
\begin{multline}
\forall q \in I_p, \exists \mathcal{P}^{pred}_{qp} \in B_p, \forall M\in B_p : \\ \neg pred(M) \vee dst(M) \ne p
\end{multline}
\end{lemma}

\begin{proof}
We can use indirect proof. Let $\langle proc, p, M^*, M' \rangle$ be a processing event that happens after the soft bound termination event but $pred(M^*)$. In other words, a message $M^*, pred(M^*)$ arrived after all punctuations for the predicate $pred$ had arrived. According to the definition of a distributed system from Section~\ref{fs-acker-processing-model}, message $M^*$ could emerge either from the mailbox of a process or incoming channels. The emergence from the mailbox contradicts the condition of the termination event generation rule $\forall M\in B : \neg pred(M) \vee dst(M) \ne p$.
Conversely, if an element comes from an incoming channel, we can track its path through the system from a data source to the channel (processing path). Because of broadcasts on each step, punctuations travel all possible paths in the system, including the path that traveled the element. Along this path, they were reordered. It could happen either during transmission or during processing. The first hypothesis contradicts the FIFO nature of communication channels. The second one is impossible due to the definition of the processing model that protects a processing order. We have excluded all possible ways of getting event $M^*$ and must reject the initial hypothesis.
\end{proof}

To satisfy the firm bound guarantee, the mailbox controller should block the processing of all incoming messages from a channel as soon as it receives punctuation from this channel. In~\cite{Carbone:2017:SMA:3137765.3137777}, such behavior is called {\em watermark (punctuation) alignment}. Formally we can rewrite this requirement in terms of event ordering:

\begin{lemma}
A soft bound becomes firm if a process event order satisfies the following conditions:
\begin{multline}
\label{eq:firm_condition}
\forall e_1, e_2 = \langle recv, p, \mathcal{P}^{pred}_{q_{1,2}p} \rangle, \nexists e' = \\ \langle proc, p, M_{q_1p}, M' \rangle, e_1 <_p e' <_p e_2
\end{multline}
\end{lemma}
\begin{proof}
Suppose a message $M_{qp}$ of the next substream was processed after the last element of the current substream but before the generation of a bound event. This message either came from the channel $q$ before the punctuation from that channel or was processed before all channels delivered their punctuations. The first case could happen if $M_{qp}$ was reordered with the punctuation along the processing path and contradicts FIFO processing logic (see previous proof for details). The second case is impossible because of processing limitations introduced by~\ref{eq:firm_condition}.
\end{proof}

\subsubsection{Properties of the punctuation framework}

The design of the punctuations framework implies two important properties:

\begin{enumerate}
    \item {\bf Lack of cyclic dataflows support.} Although there are techniques that extend punctuations for state snapshotting of iterative processing~\cite{Carbone:2017:SMA:3137765.3137777}, the termination of a general substream cannot be determined using the punctuation framework if an execution graph contains cycles.
    \item {\bf Network traffic complexity quadratically depends on the number of processes.} As we demonstrated above, each process waits for punctuations from all incoming network channels delivers. It leads to high network traffic overhead if all processes are interconnected.
\end{enumerate}

\begin{lemma}
The punctuation framework cannot determine a substream termination of an execution graph if the graph contains a cycle.
\end{lemma}
\begin{proof}
If we have a cycle in the processing graph, we can find a process that receives input from the latter steps of the cycle (back-link). This process will propagate a punctuation element when all incoming channels have received their punctuation elements. Due to the cycle, this punctuation element processing path contains the process itself (as a starting element of the cycle). It means that we need the punctuation to be already generated to generate it. We obtained a contradiction.
\end{proof}

Despite the previous Lemma, some punctuation-based systems report support of cyclic workflows. One can practically achieve it by limiting the number of possible entrances into the cycle by some $m$. With this limitation, we can roll out the cycle with repeating fragments of the cycle $m$ times. The first block is then connected to the input of the cycle, and the last element of the cycle to two elements: repetition entrance and the output of the cycle. Repetitions are organized the same way. Theoretically, this cycle representation is a DAG so that the punctuation mechanism can serve it.

For example, the technique proposed in~\cite{Carbone:2017:SMA:3137765.3137777} allows SPEs to use punctuations for the state snapshotting problem. The main idea of this technique is to include in a snapshot all in-transit elements (possibly from previous epochs) within a cycle and then resend them on rollback. It is the specific form of the limitation on the number of possible entrances with $m=1$.

\begin{lemma}
Network traffic complexity for this method is $O(K|\Pi|^2)$, where $|\Pi|$ is the number of processes and $K$ is the number of substreams if an SPE distributes the work among processes evenly.
\end{lemma}
\begin{proof}

Even the soft bound event requires receiving punctuations from all incoming network channels. If a distributed stream processing engine balances the work evenly among the processes, all processes are interconnected. Therefore, each active process should broadcast punctuations to all other processes. Assuming that all processes handle the elements belonging to the predicate, the transmission complexity of punctuation elements is $O(K|\Pi|^2)$. Therefore, if the number of existing substreams is $K$, then the network traffic complexity for the punctuations framework is $O(K|\Pi|^2)$ because each process should broadcast punctuations for each substream. 

\end{proof}

Several promising directions exist for improving the network traffic complexity for the punctuation framework. Firstly, one can batch punctuations for several substreams if they do not require independent termination events. It can reduce network complexity to $O(\frac{K}{B}|\Pi|^2)$ where B is a batching frequency. On the other hand, this approach is unsuitable for all substream types (e.g., it cannot be applied for epochs) and can increase the latency between the substream end and the termination event while keeping the quadratic dependency on the number of nodes.

Secondly, it is possible to attach punctuations to all regular input data elements. In this case, there can be no extra traffic in terms of messages at all. However, it makes the latency between the substream end and the termination event unpredictable because some network channels can rarely be used.

Both mentioned optimization ideas have significant trade-offs and require deep theoretical and experimental research. Therefore, we do not consider mentioned optimization ideas in this work, leaving them for future work.
