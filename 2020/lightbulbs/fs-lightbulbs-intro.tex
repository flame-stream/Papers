The change-point detection problem on a stream data is formulated in a following way. There is a stream of elements sampled from a probability distribution refers to a family of distributions $F(\theta)$ with parameter $\theta$. Changes happen after elements $M_1, M_2, \dots$ so that parameter of distribution is $\theta_0, \theta_1, \theta_2, \dots$ in the element ranges \\ $\left[ 0; M_1 \right), \left[ M_1; M_2 \right), \left[M_2; M_3 \right), \dots$ correspondingly. The problem is to detect change in distribution parameter with the smallest possible latency (number of elements between change and detection).

Lots of stream processing algorithms can be sensitive to an unexpected change in a data stream distribution. For example, in stream classification problem change of tf-idf features can lead to a massive misclassification. However, most stream processing algorithms use adaptation to changing distribution rather than applying a forgetting factor to an old data or ignoring it. Thus, we have to be able to detect change occurrences in the stream as soon as possible so as to quickly adapt the algorithm to a different distribution.

As change-point detection problem can be applied in large scale stream processing systems where data arrives with high frequency, a scalable solution for this problem is needed to be presented. Possible way of organising distibuted solution for change-point detection is to present two algorithms: an algorithm for processing element on a single node which collects the statistics and an algorithm for fusing statistics from nodes. In this work, the existing efficient algorithm was taken as a basis for a single-node algorithm and different simple rules were used for fusing statistics. 
