Jeffrey Dean and Sanjay Ghemawat. 2008. MapReduce: simplified data processing on large clusters. Commun. ACM 51, 1 (January 2008), 107-113. DOI: https://doi.org/10.1145/1327452.1327492

@article{Dean:2008:MSD:1327452.1327492,
 author = {Dean, Jeffrey and Ghemawat, Sanjay},
 title = {MapReduce: Simplified Data Processing on Large Clusters},
 journal = {Commun. ACM},
 issue_date = {January 2008},
 volume = {51},
 number = {1},
 month = jan,
 year = {2008},
 issn = {0001-0782},
 pages = {107--113},
 numpages = {7},
 url = {http://doi.acm.org/10.1145/1327452.1327492},
 doi = {10.1145/1327452.1327492},
 acmid = {1327492},
 publisher = {ACM},
 address = {New York, NY, USA},
} 
MapReduce is a programming model and an associated implementation for processing and generating large datasets that is amenable to a broad variety of real-world tasks. Users specify the computation in terms of a map and a reduce function, and the underlying runtime system automatically parallelizes the computation across large-scale clusters of machines, handles machine failures, and schedules inter-machine communication to make efficient use of the network and disks. Programmers find the system easy to use: more than ten thousand distinct MapReduce programs have been implemented internally at Google over the past four years, and an average of one hundred thousand MapReduce jobs are executed on Google's clusters every day, processing a total of more than twenty petabytes of data per day.


Carbone, P., Katsifodimos, A., Ewen, S., Markl, V., Haridi, S. and Tzoumas, K., 2015. Apache flink: Stream and batch processing in a single engine. Bulletin of the IEEE Computer Society Technical Committee on Data Engineering, 36(4).
Vancouver	

@article{carbone2015apache,
  title={Apache flink: Stream and batch processing in a single engine},
  author={Carbone, Paris and Katsifodimos, Asterios and Ewen, Stephan and Markl, Volker and Haridi, Seif and Tzoumas, Kostas},
  journal={Bulletin of the IEEE Computer Society Technical Committee on Data Engineering},
  volume={36},
  number={4},
  year={2015},
  publisher={IEEE Computer Society}
}
Apache Flink is an open-source system for processing streaming and batch data. Flink is built on the
philosophy that many classes of data processing applications, including real-time analytics, continuous
data pipelines, historic data processing (batch), and iterative algorithms (machine learning, graph
analysis) can be expressed and executed as pipelined fault-tolerant dataflows. In this paper, we present
Flink’s architecture and expand on how a (seemingly diverse) set of use cases can be unified under a
single execution model


Gábor Horváth, Norbert Pataki, and Márton Balassi. 2017. Code Generation in Serializers and Comparators of Apache Flink. In Proceedings of the 12th Workshop on Implementation, Compilation, Optimization of Object-Oriented Languages, Programs and Systems (ICOOOLPS'17). ACM, New York, NY, USA, Article 5, 6 pages. DOI: https://proxy.library.spbu.ru:3316/10.1145/3098572.3098579

@inproceedings{Horvath:2017:CGS:3098572.3098579,
 author = {Horv\'{a}th, G\'{a}bor and Pataki, Norbert and Balassi, M\'{a}rton},
 title = {Code Generation in Serializers and Comparators of Apache Flink},
 booktitle = {Proceedings of the 12th Workshop on Implementation, Compilation, Optimization of Object-Oriented Languages, Programs and Systems},
 series = {ICOOOLPS'17},
 year = {2017},
 isbn = {978-1-4503-5088-4},
 location = {Barcelona, Spain},
 pages = {5:1--5:6},
 articleno = {5},
 numpages = {6},
 url = {http://proxy.library.spbu.ru:2393/10.1145/3098572.3098579},
 doi = {10.1145/3098572.3098579},
 acmid = {3098579},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Flink, Janino, Java, big data, code generation},
} 

here is a shift in the Big Data world. Applications used to be I/O bound. InfiniBand, SSDs reduced the I/O overhead and more sophisticated algorithms were developed. CPU became a bottleneck for some applications. Using state of the art CPUs, reduced CPU usage can lead to reduced electricity costs even when an application is I/O bound.

Apache Flink is an open source framework for processing streams of data and batch jobs. It is using serialization for wide variety of purposes. Not only for sending data over the network, saving it to the hard disk, or for fault tolerance, but also some of the operators can work on the serialized representation of the data instead of Java objects. This approach can improve the performance significantly. Flink has a custom serialization method that enables operators to work on the serialized formats.

Currently, Apache Flink uses reflection to serialize Plain Old Java Objects (POJOs). Reflection in Java is notoriously slow. Moreover, the structure of the code is harder to optimize for the JIT compiler. As a Google Summer of Code project in 2016, we implemented code generation for serializers and comparators for POJOs to improve the performance of Apache Flink. Flink has a delicate type system which provides us with lots of information about the types that need to be serialized. Using this information it is possible to generate specialized code with great performance.

We achieved more than 6X performance improvement in the serialization which was a 20% overall improvement.


Christos Doulkeridis and Kjetil NØrvåg. 2014. A survey of large-scale analytical query processing in MapReduce. The VLDB Journal 23, 3 (June 2014), 355-380. DOI=http://proxy.library.spbu.ru:2083/10.1007/s00778-013-0319-9

@article{Doulkeridis:2014:SLA:2628707.2628782,
 author = {Doulkeridis, Christos and Norvaag, Kjetil},
 title = {A Survey of Large-scale Analytical Query Processing in MapReduce},
 journal = {The VLDB Journal},
 issue_date = {June      2014},
 volume = {23},
 number = {3},
 month = jun,
 year = {2014},
 issn = {1066-8888},
 pages = {355--380},
 numpages = {26},
 url = {http://proxy.library.spbu.ru:2083/10.1007/s00778-013-0319-9},
 doi = {10.1007/s00778-013-0319-9},
 acmid = {2628782},
 publisher = {Springer-Verlag New York, Inc.},
 address = {Secaucus, NJ, USA},
 keywords = {Big Data, Data analysis, Large-scale, MapReduce, Query processing, Survey},
} 
Enterprises today acquire vast volumes of data from different sources and leverage this information by means of data analysis to support effective decision-making and provide new functionality and services. The key requirement of data analytics is scalability, simply due to the immense volume of data that need to be extracted, processed, and analyzed in a timely fashion. Arguably the most popular framework for contemporary large-scale data analytics is MapReduce, mainly due to its salient features that include scalability, fault-tolerance, ease of programming, and flexibility. However, despite its merits, MapReduce has evident performance limitations in miscellaneous analytical tasks, and this has given rise to a significant body of research that aim at improving its efficiency, while maintaining its desirable properties. This survey aims to review the state of the art in improving the performance of parallel query processing using MapReduce. A set of the most significant weaknesses and limitations of MapReduce is discussed at a high level, along with solving techniques. A taxonomy is presented for categorizing existing research on MapReduce improvements according to the specific problem they target. Based on the proposed taxonomy, a classification of existing research is provided focusing on the optimization objective. Concluding, we outline interesting directions for future parallel data processing systems.


Sattam Alsubaiee, Alexander Behm, Raman Grover, Rares Vernica, Vinayak Borkar, Michael J. Carey, and Chen Li. 2012. ASTERIX: scalable warehouse-style web data integration. In Proceedings of the Ninth International Workshop on Information Integration on the Web (IIWeb '12). ACM, New York, NY, USA, , Article 2 , 4 pages. DOI=http://proxy.library.spbu.ru:2083/10.1145/2331801.2331803

@inproceedings{Alsubaiee:2012:ASW:2331801.2331803,
 author = {Alsubaiee, Sattam and Behm, Alexander and Grover, Raman and Vernica, Rares and Borkar, Vinayak and Carey, Michael J. and Li, Chen},
 title = {ASTERIX: Scalable Warehouse-style Web Data Integration},
 booktitle = {Proceedings of the Ninth International Workshop on Information Integration on the Web},
 series = {IIWeb '12},
 year = {2012},
 isbn = {978-1-4503-1239-4},
 location = {Scottsdale, Arizona, USA},
 pages = {2:1--2:4},
 articleno = {2},
 numpages = {4},
 url = {http://proxy.library.spbu.ru:2393/10.1145/2331801.2331803},
 doi = {10.1145/2331801.2331803},
 acmid = {2331803},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {ASTERIX, cloud computing, data-intensive computing, hyracks, semistructured data},
} 
A growing wealth of digital information is being generated on a daily basis in social networks, blogs, online communities, etc. Organizations and researchers in a wide variety of domains recognize that there is tremendous value and insight to be gained by warehousing this emerging data and making it available for querying, analysis, and other purposes. This new breed of "Big Data" applications poses challenging requirements against data management platforms in terms of scalability, flexibility, manageability, and analysis capabilities. At UC Irvine, we are building a next-generation database system, called ASTERIX, in response to these trends. We present ongoing work that approaches the following questions: How does data get into the system? What primitives should we provide to better cope with dirty/noisy data? How can we support efficient data analysis on spatial data? Using real examples, we show the capabilities of ASTERIX for ingesting data via feeds, supporting set-similarity predicates for fuzzy matching, and answering spatial aggregation queries.


@article{Carbone:2017:SMA:3137765.3137777,
 author = {Carbone, Paris and Ewen, Stephan and F\'{o}ra, Gyula and Haridi, Seif and Richter, Stefan and Tzoumas, Kostas},
 title = {State Management in Apache Flink\&Reg;: Consistent Stateful Distributed Stream Processing},
 journal = {Proc. VLDB Endow.},
 issue_date = {August 2017},
 volume = {10},
 number = {12},
 month = aug,
 year = {2017},
 issn = {2150-8097},
 pages = {1718--1729},
 numpages = {12},
 url = {https://proxy.library.spbu.ru:3316/10.14778/3137765.3137777},
 doi = {10.14778/3137765.3137777},
 acmid = {3137777},
 publisher = {VLDB Endowment},
} 
Stream processors are emerging in industry as an apparatus that drives analytical but also mission critical services handling the core of persistent application logic. Thus, apart from scalability and low-latency, a rising system need is first-class support for application state together with strong consistency guarantees, and adaptivity to cluster reconfigurations, software patches and partial failures. Although prior systems research has addressed some of these specific problems, the practical challenge lies on how such guarantees can be materialized in a transparent, non-intrusive manner that relieves the user from unnecessary constraints. Such needs served as the main design principles of state management in Apache Flink, an open source, scalable stream processor.

We present Flink's core pipelined, in-flight mechanism which guarantees the creation of lightweight, consistent, distributed snapshots of application state, progressively, without impacting continuous execution. Consistent snapshots cover all needs for system reconfiguration, fault tolerance and version management through coarse grained rollback recovery. Application state is declared explicitly to the system, allowing efficient partitioning and transparent commits to persistent storage. We further present Flink's backend implementations and mechanisms for high availability, external state queries and output commit. Finally, we demonstrate how these mechanisms behave in practice with metrics and large-deployment insights exhibiting the low performance trade-offs of our approach and the general benefits of exploiting asynchrony in continuous, yet sustainable system deployments.


Zhengping Qian, Yong He, Chunzhi Su, Zhuojie Wu, Hongyu Zhu, Taizhi Zhang, Lidong Zhou, Yuan Yu, and Zheng Zhang. 2013.
TimeStream: reliable stream computation in the cloud. In Proceedings of the 8th ACM European Conference on Computer
Systems (EuroSys '13). ACM, New York, NY, USA, 1-14. DOI=http://dx.doi.org/10.1145/2465351.2465353

@inproceedings{Qian:2013:TRS:2465351.2465353,
 author = {Qian, Zhengping and He, Yong and Su, Chunzhi and Wu, Zhuojie and Zhu, Hongyu and Zhang, Taizhi and Zhou, Lidong and Yu, Yuan and Zhang, Zheng},
 title = {TimeStream: Reliable Stream Computation in the Cloud},
 booktitle = {Proceedings of the 8th ACM European Conference on Computer Systems},
 series = {EuroSys '13},
 year = {2013},
 isbn = {978-1-4503-1994-2},
 location = {Prague, Czech Republic},
 pages = {1--14},
 numpages = {14},
 url = {http://doi.acm.org/10.1145/2465351.2465353},
 doi = {10.1145/2465351.2465353},
 acmid = {2465353},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {StreamInsight, cluster computing, distributed stream processing, dynamic reconfiguration, fault-tolerance, real-time, resilient substitution},
} 
TimeStream is a distributed system designed specifically for low-latency continuous processing of big streaming data on a large cluster of commodity machines. The unique characteristics of this emerging application domain have led to a significantly different design from the popular MapReduce-style batch data processing. In particular, we advocate a powerful new abstraction called resilient substitution that caters to the specific needs in this new computation model to handle failure recovery and dynamic reconfiguration in response to load changes. Several real-world applications running on our prototype have been shown to scale robustly with low latency while at the same time maintaining the simple and concise declarative programming model. TimeStream handles an on-line advertising aggregation pipeline at a rate of 700,000 URLs per second with a 2-second delay, while performing sentiment analysis of Twitter data at a peak rate close to 10,000 tweets per second, with approximately 2-second delay.


Sanjeev Kulkarni, Nikunj Bhagat, Maosong Fu, Vikas Kedigehalli, Christopher Kellogg, Sailesh Mittal, Jignesh M. Patel, Karthik Ramasamy, and Siddarth Taneja. 2015. Twitter Heron: Stream Processing at Scale. In Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data (SIGMOD '15). ACM, New York, NY, USA, 239-250. DOI: https://doi.org/10.1145/2723372.2742788


@inproceedings{Kulkarni:2015:THS:2723372.2742788,
 author = {Kulkarni, Sanjeev and Bhagat, Nikunj and Fu, Maosong and Kedigehalli, Vikas and Kellogg, Christopher and Mittal, Sailesh and Patel, Jignesh M. and Ramasamy, Karthik and Taneja, Siddarth},
 title = {Twitter Heron: Stream Processing at Scale},
 booktitle = {Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data},
 series = {SIGMOD '15},
 year = {2015},
 isbn = {978-1-4503-2758-9},
 location = {Melbourne, Victoria, Australia},
 pages = {239--250},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/2723372.2742788},
 doi = {10.1145/2723372.2742788},
 acmid = {2742788},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {real-time data processing., stream data processing systems},
} 
Storm has long served as the main platform for real-time analytics at Twitter. However, as the scale of data being processed in real-time at Twitter has increased, along with an increase in the diversity and the number of use cases, many limitations of Storm have become apparent. We need a system that scales better, has better debug-ability, has better performance, and is easier to manage -- all while working in a shared cluster infrastructure. We considered various alternatives to meet these needs, and in the end concluded that we needed to build a new real-time stream data processing system. This paper presents the design and implementation of this new system, called Heron. Heron is now the de facto stream data processing engine inside Twitter, and in this paper we also share our experiences from running Heron in production. In this paper, we also provide empirical evidence demonstrating the efficiency and scalability of Heron.


Matei Zaharia, Tathagata Das, Haoyuan Li, Scott Shenker, and Ion Stoica. 2012. Discretized streams: an efficient and fault-tolerant model for stream processing on large clusters. In Proceedings of the 4th USENIX conference on Hot Topics in Cloud Ccomputing (HotCloud'12). USENIX Association, Berkeley, CA, USA, 10-10.

@inproceedings{Zaharia:2012:DSE:2342763.2342773,
 author = {Zaharia, Matei and Das, Tathagata and Li, Haoyuan and Shenker, Scott and Stoica, Ion},
 title = {Discretized Streams: An Efficient and Fault-tolerant Model for Stream Processing on Large Clusters},
 booktitle = {Proceedings of the 4th USENIX Conference on Hot Topics in Cloud Ccomputing},
 series = {HotCloud'12},
 year = {2012},
 location = {Boston, MA},
 pages = {10--10},
 numpages = {1},
 url = {http://dl.acm.org/citation.cfm?id=2342763.2342773},
 acmid = {2342773},
 publisher = {USENIX Association},
 address = {Berkeley, CA, USA},
} 
Many important "big data" applications need to process data arriving in real time. However, current programming models for distributed stream processing are relatively low-level, often leaving the user to worry about consistency of state across the system and fault recovery. Furthermore, the models that provide fault recovery do so in an expensive manner, requiring either hot replication or long recovery times. We propose a new programming model, discretized streams (D-Streams), that offers a high-level functional programming API, strong consistency, and efficient fault recovery. D-Streams support a new recovery mechanism that improves efficiency over the traditional replication and upstream backup solutions in streaming databases: parallel recovery of lost state across the cluster. We have prototyped D-Streams in an extension to the Spark cluster computing framework called Spark Streaming, which lets users seamlessly intermix streaming, batch and interactive queries.


Tyler Akidau, Robert Bradshaw, Craig Chambers, Slava Chernyak, Rafael J. Fernández-Moctezuma, Reuven Lax, Sam McVeety, Daniel Mills, Frances Perry, Eric Schmidt, and Sam Whittle. 2015. The dataflow model: a practical approach to balancing correctness, latency, and cost in massive-scale, unbounded, out-of-order data processing. Proc. VLDB Endow. 8, 12 (August 2015), 1792-1803. DOI=http://dx.doi.org/10.14778/2824032.2824076

@article{Akidau:2015:DMP:2824032.2824076,
 author = {Akidau, Tyler and Bradshaw, Robert and Chambers, Craig and Chernyak, Slava and Fern\'{a}ndez-Moctezuma, Rafael J. and Lax, Reuven and McVeety, Sam and Mills, Daniel and Perry, Frances and Schmidt, Eric and Whittle, Sam},
 title = {The Dataflow Model: A Practical Approach to Balancing Correctness, Latency, and Cost in Massive-scale, Unbounded, Out-of-order Data Processing},
 journal = {Proc. VLDB Endow.},
 issue_date = {August 2015},
 volume = {8},
 number = {12},
 month = aug,
 year = {2015},
 issn = {2150-8097},
 pages = {1792--1803},
 numpages = {12},
 url = {http://dx.doi.org/10.14778/2824032.2824076},
 doi = {10.14778/2824032.2824076},
 acmid = {2824076},
 publisher = {VLDB Endowment},
} 
Unbounded, unordered, global-scale datasets are increasingly common in day-to-day business (e.g. Web logs, mobile usage statistics, and sensor networks). At the same time, consumers of these datasets have evolved sophisticated requirements, such as event-time ordering and windowing by features of the data themselves, in addition to an insatiable hunger for faster answers. Meanwhile, practicality dictates that one can never fully optimize along all dimensions of correctness, latency, and cost for these types of input. As a result, data processing practitioners are left with the quandary of how to reconcile the tensions between these seemingly competing propositions, often resulting in disparate implementations and systems.

We propose that a fundamental shift of approach is necessary to deal with these evolved requirements in modern data processing. We as a field must stop trying to groom unbounded datasets into finite pools of information that eventually become complete, and instead live and breathe under the assumption that we will never know if or when we have seen all of our data, only that new data will arrive, old data may be retracted, and the only way to make this problem tractable is via principled abstractions that allow the practitioner the choice of appropriate tradeoffs along the axes of interest: correctness, latency, and cost.

In this paper, we present one such approach, the Dataflow Model, along with a detailed examination of the semantics it enables, an overview of the core principles that guided its design, and a validation of the model itself via the real-world experiences that led to its development.


Tyler Akidau, Alex Balikov, Kaya Bekiroğlu, Slava Chernyak, Josh Haberman, Reuven Lax, Sam McVeety, Daniel Mills, Paul Nordstrom, and Sam Whittle. 2013. MillWheel: fault-tolerant stream processing at internet scale. Proc. VLDB Endow. 6, 11 (August 2013), 1033-1044. DOI: http://dx.doi.org/10.14778/2536222.2536229

@article{Akidau:2013:MFS:2536222.2536229,
 author = {Akidau, Tyler and Balikov, Alex and Bekiro\u{g}lu, Kaya and Chernyak, Slava and Haberman, Josh and Lax, Reuven and McVeety, Sam and Mills, Daniel and Nordstrom, Paul and Whittle, Sam},
 title = {MillWheel: Fault-tolerant Stream Processing at Internet Scale},
 journal = {Proc. VLDB Endow.},
 issue_date = {August 2013},
 volume = {6},
 number = {11},
 month = aug,
 year = {2013},
 issn = {2150-8097},
 pages = {1033--1044},
 numpages = {12},
 url = {http://dx.doi.org/10.14778/2536222.2536229},
 doi = {10.14778/2536222.2536229},
 acmid = {2536229},
 publisher = {VLDB Endowment},
} 
MillWheel is a framework for building low-latency data-processing applications that is widely used at Google. Users specify a directed computation graph and application code for individual nodes, and the system manages persistent state and the continuous flow of records, all within the envelope of the framework's fault-tolerance guarantees.

This paper describes MillWheel's programming model as well as its implementation. The case study of a continuous anomaly detector in use at Google serves to motivate how many of MillWheel's features are used. MillWheel's programming model provides a notion of logical time, making it simple to write time-based aggregations. MillWheel was designed from the outset with fault tolerance and scalability in mind. In practice, we find that MillWheel's unique combination of scalability, fault tolerance, and a versatile programming model lends itself to a wide variety of problems at Google.


Nathan Marz and James Warren. 2015. Big Data: Principles and Best Practices of Scalable Realtime Data Systems (1st ed.). Manning Publications Co., Greenwich, CT, USA.

@book{Marz:2015:BDP:2717065,
 author = {Marz, Nathan and Warren, James},
 title = {Big Data: Principles and Best Practices of Scalable Realtime Data Systems},
 year = {2015},
 isbn = {1617290343, 9781617290343},
 edition = {1st},
 publisher = {Manning Publications Co.},
 address = {Greenwich, CT, USA},
} 
Services like social networks, web analytics, and intelligent e-commerce often need to manage data at a scale too big for a traditional database. As scale and demand increase, so does Complexity. Fortunately, scalability and simplicity are not mutually exclusiverather than using some trendy technology, a different approach is needed. Big data systems use many machines working in parallel to store and process data, which introduces fundamental challenges unfamiliar to most developers. Big Data shows how to build these systems using an architecture that takes advantage of clustered hardware along with new tools designed specifically to capture and analyze web-scale data. It describes a scalable, easy to understand approach to big data systems that can be built and run by a small team. Following a realistic example, this book guides readers through the theory of big data systems, how to use them in practice, and how to deploy and operate them once they're built. Purchase of the print book comes with an offer of a free PDF, ePub, and Kindle eBook from Manning. Also available is all code from the book.


Michael Franklin. 2015. Making Sense of Big Data with the Berkeley Data Analytics Stack. In Proceedings of the Eighth ACM International Conference on Web Search and Data Mining (WSDM '15). ACM, New York, NY, USA, 1-2. DOI: http://proxy.library.spbu.ru:2083/10.1145/2684822.2685326

@inproceedings{Franklin:2015:MSB:2684822.2685326,
 author = {Franklin, Michael},
 title = {Making Sense of Big Data with the Berkeley Data Analytics Stack},
 booktitle = {Proceedings of the Eighth ACM International Conference on Web Search and Data Mining},
 series = {WSDM '15},
 year = {2015},
 isbn = {978-1-4503-3317-7},
 location = {Shanghai, China},
 pages = {1--2},
 numpages = {2},
 url = {http://proxy.library.spbu.ru:2393/10.1145/2684822.2685326},
 doi = {10.1145/2684822.2685326},
 acmid = {2685326},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {big data},
} 

The Berkeley AMPLab is creating a new approach to data analytics. Launching in early 2011, the lab aims to seamlessly integrate the three main resources available for making sense of data at scale: Algorithms (machine learning and statistical techniques), Machines (in the form of scalable clusters and elastic cloud computing), and People (both individually as analysts and in crowds). The lab is realizing its ideas through the development of a freely-available Open Source software stack called BDAS: the Berkeley Data Analytics Stack. In the four years the lab has been in operation, we've released major components of BDAS. Several of these components have gained significant traction in industry and elsewhere: the Mesos cluster resource manager, the Spark in-memory computation framework, and the Shark query processing system. BDAS features prominently in many industry discussions of the future of the Big Data analytics ecosystem -- a rare degree of impact for an ongoing academic project. Given this initial success, the lab is continuing on its research path, moving "up the stack" to better integrate and support advanced analytics and to make people a full-fledged resource for making sense of data. In this talk, I'll first outline the motivation and insights behind our research approach and describe how we have organized to address the cross-disciplinary nature of Big Data challenges. I will then describe the current state of BDAS with an emphasis on our newest efforts, including some or all of: the GraphX graph processing system, the Velox and MLBase machine learning platforms, and the SampleClean framework for hybrid human/computer data cleaning. Finally I will present our current views of how all the pieces will fit together to form a system that can adaptively bring the right resources to bear on a given data-driven question to meet time, cost and quality requirements throughout the analytics lifecycle.

Matei Zaharia, Reynold S. Xin, Patrick Wendell, Tathagata Das, Michael Armbrust, Ankur Dave, Xiangrui Meng, Josh Rosen, Shivaram Venkataraman, Michael J. Franklin, Ali Ghodsi, Joseph Gonzalez, Scott Shenker, and Ion Stoica. 2016. Apache Spark: a unified engine for big data processing. Commun. ACM 59, 11 (October 2016), 56-65. DOI: https://proxy.library.spbu.ru:3316/10.1145/2934664

@article{Zaharia:2016:ASU:3013530.2934664,
 author = {Zaharia, Matei and Xin, Reynold S. and Wendell, Patrick and Das, Tathagata and Armbrust, Michael and Dave, Ankur and Meng, Xiangrui and Rosen, Josh and Venkataraman, Shivaram and Franklin, Michael J. and Ghodsi, Ali and Gonzalez, Joseph and Shenker, Scott and Stoica, Ion},
 title = {Apache Spark: A Unified Engine for Big Data Processing},
 journal = {Commun. ACM},
 issue_date = {November 2016},
 volume = {59},
 number = {11},
 month = oct,
 year = {2016},
 issn = {0001-0782},
 pages = {56--65},
 numpages = {10},
 url = {http://proxy.library.spbu.ru:2393/10.1145/2934664},
 doi = {10.1145/2934664},
 acmid = {2934664},
 publisher = {ACM},
 address = {New York, NY, USA},
} 
This open source computing framework unifies streaming, batch, and interactive big data workloads to unlock new applications.


Fidge, C.J., 1987. Timestamps in message-passing systems that preserve the partial ordering.

@article{fidge1988timestamps,
  added-at = {2012-01-14T13:04:26.000+0100},
  author = {Fidge, C. J.},
  biburl = {https://www.bibsonomy.org/bibtex/2cc829c490de6ff6203758943b4d3ca84/nosebrain},
  description = {Timestamps in message-passing systems that preserve the partial ordering | Mendeley},
  interhash = {27bbdd2f31ec6e29b97770b3e017cddc},
  intrahash = {cc829c490de6ff6203758943b4d3ca84},
  journal = {Proceedings of the 11th Australian Computer Science Conference},
  keywords = {clock vector},
  number = 1,
  pages = {56–66},
  timestamp = {2012-01-14T13:04:26.000+0100},
  title = {Timestamps in message-passing systems that preserve the partial ordering},
  url = {http://sky.scitech.qut.edu.au/~fidgec/Publications/fidge88a.pdf},
  volume = 10,
  year = 1988
}
Timestamping is a common method of totally ordering events in concurrent programs. However, for applications requiring access to the global state, a total ordering is inappropriate. This paper presents algorithms for timestamping events in both synchronous and asynchronous n1essage-passing programs that allow for access to the partial ordering inherent in a parallel system. The algorithms do not change the con1munications graph or require a central timestamp issuing authority. 


Mattern, F., 1989. Virtual time and global states of distributed systems. Parallel and Distributed Algorithms, 1(23), pp.215-226.

@INPROCEEDINGS{mattern88virtualtime,
    author = {Friedemann Mattern},
    title = {Virtual Time and Global States of Distributed Systems},
    booktitle = {PARALLEL AND DISTRIBUTED ALGORITHMS},
    year = {1988},
    pages = {215--226},
    publisher = {North-Holland}
}
A distributed system can be characterized by the fact that the global state is distributed and that a common time base does not exist. However, the notion of time is an important concept in every day life of our decentralized "real world" and helps to solve problems like getting a consistent population census or determining the potential causality between events. We argue that a linearly ordered structure of time is not (always) adequate for distributed systems and propose a generalized non-standardmodel of time which consists of vectors of clocks. These clock-vectors arepartially orderedand form a lattice. By using timestamps and a simple clock update mechanism the structure of causality is represented in an isomorphic way. The new model of time has a close analogy to Minkowski's relativistic spacetime and leads among others to an interesting characterization of the global state problem. Finally, we present a new algorithm to compute a consistent global snapshot of a distributed system where messages may bereceived out of order.


Derek G. Murray, Frank McSherry, Rebecca Isaacs, Michael Isard, Paul Barham, and Martín Abadi. 2013. Naiad: a timely dataflow system. In Proceedings of the Twenty-Fourth ACM Symposium on Operating Systems Principles (SOSP '13). ACM, New York, NY, USA, 439-455. DOI: https://doi.org/10.1145/2517349.2522738

@inproceedings{Murray:2013:NTD:2517349.2522738,
 author = {Murray, Derek G. and McSherry, Frank and Isaacs, Rebecca and Isard, Michael and Barham, Paul and Abadi, Mart\'{\i}n},
 title = {Naiad: A Timely Dataflow System},
 booktitle = {Proceedings of the Twenty-Fourth ACM Symposium on Operating Systems Principles},
 series = {SOSP '13},
 year = {2013},
 isbn = {978-1-4503-2388-8},
 location = {Farminton, Pennsylvania},
 pages = {439--455},
 numpages = {17},
 url = {http://doi.acm.org/10.1145/2517349.2522738},
 doi = {10.1145/2517349.2522738},
 acmid = {2522738},
 publisher = {ACM},
 address = {New York, NY, USA},
} 
Naiad is a distributed system for executing data parallel, cyclic dataflow programs. It offers the high throughput of batch processors, the low latency of stream processors, and the ability to perform iterative and incremental computations. Although existing systems offer some of these features, applications that require all three have relied on multiple platforms, at the expense of efficiency, maintainability, and simplicity. Naiad resolves the complexities of combining these features in one framework.

A new computational model, timely dataflow, underlies Naiad and captures opportunities for parallelism across a wide class of algorithms. This model enriches dataflow computation with timestamps that represent logical points in the computation and provide the basis for an efficient, lightweight coordination mechanism.

We show that many powerful high-level programming models can be built on Naiad's low-level primitives, enabling such diverse tasks as streaming data analysis, iterative machine learning, and interactive graph mining. Naiad outperforms specialized systems in their target application domains, and its unique features enable the development of new high-performance applications.

@online{amazon:kinesis,
  title = {Amazon Kinesis},
  url = {https://aws.amazon.com/kinesis/}
}
Amazon Kinesis makes it easy to collect, process, and analyze real-time, streaming data so you can get timely insights and react quickly to new information. Amazon Kinesis offers key capabilities to cost effectively process streaming data at any scale, along with the flexibility to choose the tools that best suit the requirements of your application. With Amazon Kinesis, you can ingest real-time data such as application logs, website clickstreams, IoT telemetry data, and more into your databases, data lakes and data warehouses, or build your own real-time applications using this data. Amazon Kinesis enables you to process and analyze data as it arrives and respond in real-time instead of having to wait until all your data is collected before the processing can begin.

@online{apache:flink:state,
  month = feb,
  year = {2018},
  title = {Apache Flink documentation, Working with State},
  url = {https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/stream/state/state.html}
}

@online{apache:storm:state,
  month = feb,
  year = {2018},
  title = {Apache Storm documentation, Storm State Management},
  url = {http://storm.apache.org/releases/1.2.1/State-checkpointing.html}
}

@online{hadoop2009hadoop,
  month = oct,
  year = {2017},
  title={Apache Hadoop},
  url = {http://hadoop.apache.org/}
}

@online{apache:storm,
  month = oct,
  year = {2017},
  title={Apache Storm},
  url = {http://storm.apache.org/}
}
Apache Storm is a free and open source distributed realtime computation system. Storm makes it easy to reliably process unbounded streams of data, doing for realtime processing what sp did for batch processing. Storm is simple, can be used with any programming language, and is a lot of fun to use!

Storm has many use cases: realtime analytics, online machine learning, continuous computation, distributed RPC, ETL, and more. Storm is fast: a benchmark clocked it at over a million tuples processed per second per node. It is scalable, fault-tolerant, guarantees your data will be processed, and is easy to set up and operate.

Storm integrates with the queueing and database technologies you already use. A Storm topology consumes streams of data and processes those streams in arbitrarily complex ways, repartitioning the streams between each stage of the computation however needed. Read more in the tutorial.


Shadi A. Noghabi, Kartik Paramasivam, Yi Pan, Navina Ramesh, Jon Bringhurst, Indranil Gupta, and Roy H. Campbell. 2017. Samza: stateful scalable stream processing at LinkedIn. Proc. VLDB Endow. 10, 12 (August 2017), 1634-1645. DOI: https://doi.org/10.14778/3137765.3137770

@article{Noghabi:2017:SSS:3137765.3137770,
 author = {Noghabi, Shadi A. and Paramasivam, Kartik and Pan, Yi and Ramesh, Navina and Bringhurst, Jon and Gupta, Indranil and Campbell, Roy H.},
 title = {Samza: Stateful Scalable Stream Processing at LinkedIn},
 journal = {Proc. VLDB Endow.},
 issue_date = {August 2017},
 volume = {10},
 number = {12},
 month = aug,
 year = {2017},
 issn = {2150-8097},
 pages = {1634--1645},
 numpages = {12},
 url = {https://doi.org/10.14778/3137765.3137770},
 doi = {10.14778/3137765.3137770},
 acmid = {3137770},
 publisher = {VLDB Endowment},
} 
Distributed stream processing systems need to support stateful processing, recover quickly from failures to resume such processing, and reprocess an entire data stream quickly. We present Apache Samza, a distributed system for stateful and fault-tolerant stream processing. Samza utilizes a partitioned local state along with a low-overhead background changelog mechanism, allowing it to scale to massive state sizes (hundreds of TB) per application. Recovery from failures is sped up by re-scheduling based on Host Affinity. In addition to processing infinite streams of events, Samza supports processing a finite dataset as a stream, from either a streaming source (e.g., Kafka), a database snapshot (e.g., Databus), or a file system (e.g. HDFS), without having to change the application code (unlike the popular Lambda-based architectures which necessitate maintenance of separate code bases for batch and stream path processing).

Samza is currently in use at LinkedIn by hundreds of production applications with more than 10, 000 containers. Samza is an open-source Apache project adopted by many top-tier companies (e.g., LinkedIn, Uber, Netflix, TripAdvisor, etc.). Our experiments show that Samza: a) handles state efficiently, improving latency and throughput by more than 100X compared to using a remote storage; b) provides recovery time independent of state size; c) scales performance linearly with number of containers; and d) supports reprocessing of the data stream quickly and with minimal interference on real-time traffic.


Hunt, P., Konar, M., Junqueira, F.P. and Reed, B., 2010, June. ZooKeeper: Wait-free Coordination for Internet-scale Systems. In USENIX annual technical conference (Vol. 8, p. 9).

@inproceedings{hunt2010zookeeper,
  title={ZooKeeper: Wait-free Coordination for Internet-scale Systems.},
  author={Hunt, Patrick and Konar, Mahadev and Junqueira, Flavio Paiva and Reed, Benjamin},
  booktitle={USENIX annual technical conference},
  volume={8},
  pages={9},
  year={2010},
  organization={Boston, MA, USA}
}
In this paper, we describe ZooKeeper, a service for coordinating
processes of distributed applications. Since
ZooKeeper is part of critical infrastructure, ZooKeeper
aims to provide a simple and high performance kernel
for building more complex coordination primitives at the
client. It incorporates elements from group messaging,
shared registers, and distributed lock services in a replicated,
centralized service. The interface exposed by ZooKeeper
has the wait-free aspects of shared registers with
an event-driven mechanism similar to cache invalidations
of distributed file systems to provide a simple, yet powerful
coordination service.
The ZooKeeper interface enables a high-performance
service implementation. In addition to the wait-free
property, ZooKeeper provides a per client guarantee of
FIFO execution of requests and linearizability for all requests
that change the ZooKeeper state. These design decisions
enable the implementation of a high performance
processing pipeline with read requests being satisfied by
local servers. We show for the target workloads, 2:1
to 100:1 read to write ratio, that ZooKeeper can handle
tens to hundreds of thousands of transactions per second.
This performance allows ZooKeeper to be used extensively
by client applications.


Kreps, J., Narkhede, N. and Rao, J., 2011, June. Kafka: A distributed messaging system for log processing. In Proceedings of the NetDB (pp. 1-7).

@inproceedings{kreps2011kafka,
  title={Kafka: A distributed messaging system for log processing},
  author={Kreps, Jay and Narkhede, Neha and Rao, Jun and others},
  year={2011}
}
Log processing has become a critical component of the data
pipeline for consumer internet companies. We introduce Kafka, a
distributed messaging system that we developed for collecting and
delivering high volumes of log data with low latency. Our system
incorporates ideas from existing log aggregators and messaging
systems, and is suitable for both offline and online message
consumption. We made quite a few unconventional yet practical
design choices in Kafka to make our system efficient and scalable.
Our experimental results show that Kafka has superior
performance when compared to two popular messaging systems.
We have been using Kafka in production for some time and it is
processing hundreds of gigabytes of new data each day.


Michael Isard, Mihai Budiu, Yuan Yu, Andrew Birrell, and Dennis Fetterly. 2007. Dryad: distributed data-parallel programs from sequential building blocks. In Proceedings of the 2nd ACM SIGOPS/EuroSys European Conference on Computer Systems 2007 (EuroSys '07). ACM, New York, NY, USA, 59-72. DOI=http://dx.doi.org/10.1145/1272996.1273005
@inproceedings{Isard:2007:DDD:1272996.1273005,
 author = {Isard, Michael and Budiu, Mihai and Yu, Yuan and Birrell, Andrew and Fetterly, Dennis},
 title = {Dryad: Distributed Data-parallel Programs from Sequential Building Blocks},
 booktitle = {Proceedings of the 2Nd ACM SIGOPS/EuroSys European Conference on Computer Systems 2007},
 series = {EuroSys '07},
 year = {2007},
 isbn = {978-1-59593-636-3},
 location = {Lisbon, Portugal},
 pages = {59--72},
 numpages = {14},
 url = {http://doi.acm.org/10.1145/1272996.1273005},
 doi = {10.1145/1272996.1273005},
 acmid = {1273005},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {cluster computing, concurrency, dataflow, distributed programming},
} 
Dryad is a general-purpose distributed execution engine for coarse-grain data-parallel applications. A Dryad application combines computational "vertices" with communication "channels" to form a dataflow graph. Dryad runs the application by executing the vertices of this graph on a set of available computers, communicating as appropriate through flies, TCP pipes, and shared-memory FIFOs.

The vertices provided by the application developer are quite simple and are usually written as sequential programs with no thread creation or locking. Concurrency arises from Dryad scheduling vertices to run simultaneously on multiple computers, or on multiple CPU cores within a computer. The application can discover the size and placement of data at run time, and modify the graph as the computation progresses to make efficient use of the available resources.

Dryad is designed to scale from powerful multi-core single computers, through small clusters of computers, to data centers with thousands of computers. The Dryad execution engine handles all the difficult problems of creating a large distributed, concurrent application: scheduling the use of computers and their CPUs, recovering from communication or computer failures, and transporting data between vertices.

@INPROCEEDINGS{4279071, 
author={M. Li and M. Liu and L. Ding and E. A. Rundensteiner and M. Mani}, 
booktitle={Distributed Computing Systems Workshops, 2007. ICDCSW '07. 27th International Conference on}, 
title={Event Stream Processing with Out-of-Order Data Arrival}, 
year={2007}, 
volume={}, 
number={}, 
pages={67-67}, 
keywords={algebra;data handling;distributed processing;mathematical operators;RFID tracking;core stream algebra operators;distributed computing environment;even machine failure;event pattern queries;event stream processing;out-of-order data arrival;real-time intrusion detection;supply chain management;Algebra;Data analysis;Data mining;Delay;Engines;Face;Intrusion detection;Out of order;Radiofrequency identification;Supply chain management}, 
doi={10.1109/ICDCSW.2007.35}, 
ISSN={1545-0678}, 
month={June},}
Complex event processing has become increasingly important in modern applications, ranging from supply chain management for RFID tracking to real-time intrusion detection. The goal is to extract patterns from such event streams in order to make informed decisions in real-time. However, networking latencies and even machine failure may cause events to arrive out-of-order at the event stream processing engine. In this work, we address the problem of processing event pattern queries specified over event streams that may contain out-of-order data. First, we analyze the problems state-of-the-art event stream processing technology would experience when faced with out-of-order data arrival. We then propose a new solution of physical implementation strategies for the core stream algebra operators such as sequence scan and pattern construction, including stack- based data structures and associated purge algorithms. Optimizations for sequence scan and construction as well as state purging to minimize CPU cost and memory consumption are also introduced. Lastly, we conduct an experimental study demonstrating the effectiveness of our approach.

@inproceedings{Wei:2009:SSO:1559845.1559973,
 author = {Wei, Mingzhu and Liu, Mo and Li, Ming and Golovnya, Denis and Rundensteiner, Elke A. and Claypool, Kajal},
 title = {Supporting a Spectrum of Out-of-order Event Processing Technologies: From Aggressive to Conservative Methodologies},
 booktitle = {Proceedings of the 2009 ACM SIGMOD International Conference on Management of Data},
 series = {SIGMOD '09},
 year = {2009},
 isbn = {978-1-60558-551-2},
 location = {Providence, Rhode Island, USA},
 pages = {1031--1034},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/1559845.1559973},
 doi = {10.1145/1559845.1559973},
 acmid = {1559973},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {complex event processing, out-of-order data, stream processing},
} 
This demonstration presents a complex event processing system which focuses on out-of-order handling. State-of-the-art event stream processing technology experiences significant challenges when faced with out-of-order data arrival including huge system latencies, missing results, and incorrect result generation. We propose two out-of-order handling techniques, conservative and aggressive strategies. We will show the efficiency of our techniques and how they can satisfy various QoS requirements of different applications.

@article{Mutschler:2014:ASP:2659232.2633686,
 author = {Mutschler, Christopher and Philippsen, Michael},
 title = {Adaptive Speculative Processing of Out-of-Order Event Streams},
 journal = {ACM Trans. Internet Technol.},
 issue_date = {July 2014},
 volume = {14},
 number = {1},
 month = aug,
 year = {2014},
 issn = {1533-5399},
 pages = {4:1--4:24},
 articleno = {4},
 numpages = {24},
 url = {http://doi.acm.org/10.1145/2633686},
 doi = {10.1145/2633686},
 acmid = {2633686},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Distributed event processing, low latency, message-oriented middleware, out-of-order event processing, publish/subscribe, speculative processing},
} 
Distributed event-based systems are used to detect meaningful events with low latency in high data-rate event streams that occur in surveillance, sports, finances, etc. However, both known approaches to dealing with the predominant out-of-order event arrival at the distributed detectors have their shortcomings: buffering approaches introduce latencies for event ordering, and stream revision approaches may result in system overloads due to unbounded retraction cascades.
This article presents an adaptive speculative processing technique for out-of-order event streams that enhances typical buffering approaches. In contrast to other stream revision approaches developed so far, our novel technique encapsulates the event detector, uses the buffering technique to delay events but also speculatively processes a portion of it, and adapts the degree of speculation at runtime to fit the available system resources so that detection latency becomes minimal.
Our technique outperforms known approaches on both synthetical data and real sensor data from a realtime locating system (RTLS) with several thousands of out-of-order sensor events per second. Speculative buffering exploits system resources and reduces latency by 40 percent on average.

@article{Li:2008:OPN:1453856.1453890,
 author = {Li, Jin and Tufte, Kristin and Shkapenyuk, Vladislav and Papadimos, Vassilis and Johnson, Theodore and Maier, David},
 title = {Out-of-order Processing: A New Architecture for High-performance Stream Systems},
 journal = {Proc. VLDB Endow.},
 issue_date = {August 2008},
 volume = {1},
 number = {1},
 month = aug,
 year = {2008},
 issn = {2150-8097},
 pages = {274--288},
 numpages = {15},
 url = {http://dx.doi.org/10.14778/1453856.1453890},
 doi = {10.14778/1453856.1453890},
 acmid = {1453890},
 publisher = {VLDB Endowment},
} 
Many stream-processing systems enforce an order on data streams during query evaluation to help unblock blocking operators and purge state from stateful operators. Such in-order processing (IOP) systems not only must enforce order on input streams, but also require that query operators preserve order. This order-preserving requirement constrains the implementation of stream systems and incurs significant performance penalties, particularly for memory consumption. Especially for high-performance, potentially distributed stream systems, the cost of enforcing order can be prohibitive. We introduce a new architecture for stream systems, out-of-order processing (OOP), that avoids ordering constraints. The OOP architecture frees stream systems from the burden of order maintenance by using explicit stream progress indicators, such as punctuation or heartbeats, to unblock and purge operators. We describe the implementation of OOP stream systems and discuss the benefits of this architecture in depth. For example, the OOP approach has proven useful for smoothing workload bursts caused by expensive end-of-window operations, which can overwhelm internal communication paths in IOP approaches. We have implemented OOP in two stream systems, Gigascope and NiagaraST. Our experimental study shows that the OOP approach can significantly outperform IOP in a number of aspects, including memory, throughput and latency.

@inproceedings{Cranor:2003:GSD:872757.872838,
 author = {Cranor, Chuck and Johnson, Theodore and Spataschek, Oliver and Shkapenyuk, Vladislav},
 title = {Gigascope: A Stream Database for Network Applications},
 booktitle = {Proceedings of the 2003 ACM SIGMOD International Conference on Management of Data},
 series = {SIGMOD '03},
 year = {2003},
 isbn = {1-58113-634-X},
 location = {San Diego, California},
 pages = {647--651},
 numpages = {5},
 url = {http://doi.acm.org/10.1145/872757.872838},
 doi = {10.1145/872757.872838},
 acmid = {872838},
 publisher = {ACM},
 address = {New York, NY, USA},
} 
We have developed Gigascope, a stream database for network applications including traffic analysis, intrusion detection, router configuration analysis, network research, network monitoring, and performance monitoring and debugging. Gigascope is undergoing installation at many sites within the AT&T network, including at OC48 routers, for detailed monitoring. In this paper we describe our motivation for and constraints in developing Gigascope, the Gigascope architecture and query language, and performance issues. We conclude with a discussion of stream database research problems we have found in our application.

@article{hammad2004optimizing,
  title={Optimizing in-order execution of continuous queries over streamed sensor data},
  author={Hammad, Moustafa and Aref, Walid and Elmagarmid, Ahmed},
  year={2004},
  publisher={University of Calgary}
}
The widespread use of sensor networks in scientific and
engineering applications leads to increased demand on the
efficient computation of the collected sensor data. Recent
research in sensor and stream data systems adopts the notion
of sliding windows to process continuous queries over
infinite sensor readings. Ordered processing of input data is
essential during query execution for many application scenarios.
In this paper we present three approaches for ordered
execution of continuous sliding window queries over
sensor data. The first approach enforces ordered processing
at the input side of the query execution plan. In the second
approach we utilize the advantage of out-of-order execution
to optimize query operators and enforce an ordered
release of the output results. The third approach is adaptive
and switches between the first and second approaches
to achieve the best overall performance with current input
arrival rates and level of multiprogramming. We study the
performance of the proposed approaches both analytically
and experimentally and under a variety of conditions such
as the asynchronous arrival of input data, and various levels
of multiprogramming. Our performance study is based
on an extensive set of experiments using a realization of the
proposed approaches in a prototype stream query processing
system.

@article{Tucker:2003:EPS:776752.776780,
 author = {Tucker, Peter A. and Maier, David and Sheard, Tim and Fegaras, Leonidas},
 title = {Exploiting Punctuation Semantics in Continuous Data Streams},
 journal = {IEEE Trans. on Knowl. and Data Eng.},
 issue_date = {March 2003},
 volume = {15},
 number = {3},
 month = mar,
 year = {2003},
 issn = {1041-4347},
 pages = {555--568},
 numpages = {14},
 url = {http://dx.doi.org/10.1109/TKDE.2003.1198390},
 doi = {10.1109/TKDE.2003.1198390},
 acmid = {776780},
 publisher = {IEEE Educational Activities Department},
 address = {Piscataway, NJ, USA},
 keywords = {Continuous queries, stream semantics, continuous data streams, query operators, stream iterators.},
}
As most current query processing architectures are already pipelined, it seems logical to apply them to data streams. However, two classes of query operators are impractical for processing long or infinite data streams. Unbounded stateful operators maintain state with no upper bound in size and, so, run out of memory. Blocking operators read an entire input before emitting a single output and, so, might never produce a result. We believe that a priori knowledge of a data stream can permit the use of such operators in some cases. We discuss a kind of stream semantics called punctuated streams. Punctuations in a stream mark the end of substreams allowing us to view an infinite stream as a mixture of finite streams. We introduce three kinds of invariants to specify the proper behavior of operators in the presence of punctuation. Pass invariants define when results can be passed on. Keep invariants define what must be kept in local state to continue successful operation. Propagation invariants define when punctuation can be passed on. We report on our initial implementation and show a strategy for proving implementations of these invariants are faithful to their relational counterparts.

@inproceedings{Srivastava:2004:FTM:1055558.1055596,
 author = {Srivastava, Utkarsh and Widom, Jennifer},
 title = {Flexible Time Management in Data Stream Systems},
 booktitle = {Proceedings of the Twenty-third ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems},
 series = {PODS '04},
 year = {2004},
 isbn = {158113858X},
 location = {Paris, France},
 pages = {263--274},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/1055558.1055596},
 doi = {10.1145/1055558.1055596},
 acmid = {1055596},
 publisher = {ACM},
 address = {New York, NY, USA},
} 
Continuous queries in a Data Stream Management System (DSMS) rely on time as a basis for windows on streams and for defining a consistent semantics for multiple streams and updatable relations. The system clock in a centralized DSMS provides a convenient and well-behaved notion of time, but often it is more appropriate for a DSMS application to define its own notion of time---its own clock(s), sequence numbers, or other forms of ordering and times-tamping. Flexible application-defined time poses challenges to the DSMS, since streams may be out of order and uncoordinated with each other, they may incur latency reaching the DSMS, and they may pause or stop. We formalize these challenges and specify how to generate heartbeats so that queries can be evaluated correctly and continuously in an application-defined time domain. Our heartbeat generation algorithm is based on parameters capturing skew between streams, unordering within streams, and latency in streams reaching the DSMS. We also describe how to estimate these parameters at run-time, and we discuss how heartbeats can be used for processing continuous queries.

@article{Babu:2004:EKC:1016028.1016032,
 author = {Babu, Shivnath and Srivastava, Utkarsh and Widom, Jennifer},
 title = {Exploiting K-constraints to Reduce Memory Overhead in Continuous Queries over Data Streams},
 journal = {ACM Trans. Database Syst.},
 issue_date = {September 2004},
 volume = {29},
 number = {3},
 month = sep,
 year = {2004},
 issn = {0362-5915},
 pages = {545--580},
 numpages = {36},
 url = {http://doi.acm.org/10.1145/1016028.1016032},
 doi = {10.1145/1016028.1016032},
 acmid = {1016032},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Continuous queries, constraints, data streams},
} 
Continuous queries often require significant run-time state over arbitrary data streams. However, streams may exhibit certain data or arrival patterns, or constraints, that can be detected and exploited to reduce state considerably without compromising correctness. Rather than requiring constraints to be satisfied precisely, which can be unrealistic in a data streams environment, we introduce k-constraints, where k is an adherence parameter specifying how closely a stream adheres to the constraint. (Smaller k's are closer to strict adherence and offer better memory reduction.) We present a query processing architecture, called k-Mon, that detects useful k-constraints automatically and exploits the constraints to reduce run-time state for a wide range of continuous queries. Experimental results showed dramatic state reduction, while only modest computational overhead was incurred for our constraint monitoring and query execution algorithms.

@inproceedings{Li:2007:ESP:1270388.1270975,
 author = {Li, Ming and Liu, Mo and Ding, Luping and Rundensteiner, Elke A. and Mani, Murali},
 title = {Event Stream Processing with Out-of-Order Data Arrival},
 booktitle = {Proceedings of the 27th International Conference on Distributed Computing Systems Workshops},
 series = {ICDCSW '07},
 year = {2007},
 isbn = {0-7695-2838-4},
 pages = {67--},
 url = {http://dx.doi.org/10.1109/ICDCSW.2007.35},
 doi = {10.1109/ICDCSW.2007.35},
 acmid = {1270975},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
} 
Complex event processing has become increasingly important in modern applications, ranging from supply chain management for RFID tracking to real-time intrusion detection. The goal is to extract patterns from such event streams in order to make informed decisions in real-time. However, networking latencies and even machine failure may cause events to arrive out-of-order at the event stream processing engine. In this work, we address the problem of processing event pattern queries specified over event streams that may contain out-of-order data. First, we analyze the problems state-of-the-art event stream processing technology would experience when faced with out-of-order data arrival. We then propose a new solution of physical implementation strategies for the core stream algebra operators such as sequence scan and pattern construction, including stack-based data structures and associated purge algorithms. Optimizations for sequence scan and construction as well as state purging to minimize CPU cost and memory consumption are also introduced. Lastly, we conduct an experimental study demonstrating the effectiveness of our approach.

@article{Abadi:2003:ANM:950481.950485,
 author = {Abadi, Daniel J. and Carney, Don and \c{C}etintemel, Ugur and Cherniack, Mitch and Convey, Christian and Lee, Sangdon and Stonebraker, Michael and Tatbul, Nesime and Zdonik, Stan},
 title = {Aurora: A New Model and Architecture for Data Stream Management},
 journal = {The VLDB Journal},
 issue_date = {August 2003},
 volume = {12},
 number = {2},
 month = aug,
 year = {2003},
 issn = {1066-8888},
 pages = {120--139},
 numpages = {20},
 url = {http://dx.doi.org/10.1007/s00778-003-0095-z},
 doi = {10.1007/s00778-003-0095-z},
 acmid = {950485},
 publisher = {Springer-Verlag New York, Inc.},
 address = {Secaucus, NJ, USA},
 keywords = {Continuous queries, Data stream management, Database triggers, Quality-of-service, Real-time systems},
} 
Abstract.This paper describes the basic processing model and architecture of Aurora, a new system to manage data streams for monitoring applications. Monitoring applications differ substantially from conventional business data processing. The fact that a software system must process and react to continual inputs from many sources (e.g., sensors) rather than from human operators requires one to rethink the fundamental architecture of a DBMS for this application area. In this paper, we present Aurora, a new DBMS currently under construction at Brandeis University, Brown University, and M.I.T. We first provide an overview of the basic Aurora model and architecture and then describe in detail a stream-oriented set of operators.

@article{Arasu:2006:CCQ:1146461.1146463,
 author = {Arasu, Arvind and Babu, Shivnath and Widom, Jennifer},
 title = {The CQL Continuous Query Language: Semantic Foundations and Query Execution},
 journal = {The VLDB Journal},
 issue_date = {June 2006},
 volume = {15},
 number = {2},
 month = jun,
 year = {2006},
 issn = {1066-8888},
 pages = {121--142},
 numpages = {22},
 url = {http://dx.doi.org/10.1007/s00778-004-0147-z},
 doi = {10.1007/s00778-004-0147-z},
 acmid = {1146463},
 publisher = {Springer-Verlag New York, Inc.},
 address = {Secaucus, NJ, USA},
 keywords = {Continuous queries, Data streams, Query language, Query processing},
} 
CQL, a continuous query language, is supported by the STREAM prototype data stream management system (DSMS) at Stanford. CQL is an expressive SQL-based declarative language for registering continuous queries against streams and stored relations. We begin by presenting an abstract semantics that relies only on “black-box” mappings among streams and relations. From these mappings we define a precise and general interpretation for continuous queries. CQL is an instantiation of our abstract semantics using SQL to map from relations to relations, window specifications derived from SQL-99 to map from streams to relations, and three new operators to map from relations to streams. Most of the CQL language is operational in the STREAM system. We present the structure of CQL's query execution plans as well as details of the most important components: operators, interoperator queues, synopses, and sharing of components among multiple operators and queries. Examples throughout the paper are drawn from the Linear Road benchmark recently proposed for DSMSs. We also curate a public repository of data stream applications that includes a wide variety of queries expressed in CQL. The relative ease of capturing these applications in CQL is one indicator that the language contains an appropriate set of constructs for data stream processing.

@inproceedings{Ding:2004:EWJ:1031171.1031189,
 author = {Ding, Luping and Rundensteiner, Elke A.},
 title = {Evaluating Window Joins over Punctuated Streams},
 booktitle = {Proceedings of the Thirteenth ACM International Conference on Information and Knowledge Management},
 series = {CIKM '04},
 year = {2004},
 isbn = {1-58113-874-1},
 location = {Washington, D.C., USA},
 pages = {98--107},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1031171.1031189},
 doi = {10.1145/1031171.1031189},
 acmid = {1031189},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {join algorithm, punctuation, sliding window, streaming data processing},
} 
We explore join optimizations in the presence of both time-based constraints (sliding windows) and value-based constraints (punctuations). We present the first join solution named PWJoin that exploits such combined constraints to shrink the runtime join state and to propagate punctuations to benefit downstream operators. We design a state structure for PWJoin that facilitates the exploitation of both constraint types. We also explore optimizations enabled by the interactions between window and punctuation, e.g., early punctuation propagation. The costs of the PWJoin are analyzed using a cost model. We also conduct an experimental study using CAPE continuous query system. The experimental results show that in most cases, by exploiting punctuations, PWJoin outperforms the pure window join with regard to both memory overhead and throughput. Our technique complements the joins in the literature, such as symmetric hash join or window join, to now require less runtime resources without compromising the accuracy of the result.

@inproceedings{Hammad:2005:OIE:1116877.1116897,
 author = {Hammad, Moustafa A. and Aref, Walid G. and Elmagarmid, Ahmed K.},
 title = {Optimizing In-order Execution of Continuous Queries over Streamed Sensor Data},
 booktitle = {Proceedings of the 17th International Conference on Scientific and Statistical Database Management},
 series = {SSDBM'2005},
 year = {2005},
 isbn = {1-88888-111-X},
 location = {Santa Barbara, CA},
 pages = {143--146},
 numpages = {4},
 url = {http://dl.acm.org/citation.cfm?id=1116877.1116897},
 acmid = {1116897},
 publisher = {Lawrence Berkeley Laboratory},
 address = {Berkeley, CA, US},
} 

@inproceedings{Hammad:2003:SSW:1315451.1315478,
 author = {Hammad, Moustafa A. and Franklin, Michael J. and Aref, Walid G. and Elmagarmid, Ahmed K.},
 title = {Scheduling for Shared Window Joins over Data Streams},
 booktitle = {Proceedings of the 29th International Conference on Very Large Data Bases - Volume 29},
 series = {VLDB '03},
 year = {2003},
 isbn = {0-12-722442-4},
 location = {Berlin, Germany},
 pages = {297--308},
 numpages = {12},
 url = {http://dl.acm.org/citation.cfm?id=1315451.1315478},
 acmid = {1315478},
 publisher = {VLDB Endowment},
} 
Continuous Query (CQ) systems typically exploit commonality among query expressions to achieve improved efficiency through shared processing. Recently proposed CQ systems have introduced window specifications in order to support unbounded data streams. There has been, however, little investigation of sharing for windowed query operators. In this paper, we address the shared execution of windowed joins, a core operator for CQ systems. We show that the strategy used in systems to date has a previously unreported performance flaw that can negatively impact queries with relatively small windows. We then propose two new execution strategies for shared joins. We evaluate the alternatives using both analytical models and implementation in a DBMS. The results show that one strategy, called MQT, provides the best performance over a range of workload settings.

@Article{Li2011,
author="Li, Chuan-Wen
and Gu, Yu
and Yu, Ge
and Hong, Bonghee",
title="Aggressive Complex Event Processing with Confidence over Out-of-Order Streams",
journal="Journal of Computer Science and Technology",
year="2011",
month="Jul",
day="01",
volume="26",
number="4",
pages="685--696",
abstract="In recent years, there has been a growing need for complex event processing (CEP), ranging from supply chain management to security monitoring. In many scenarios events are generated in different sources but arrive at the central server out of order, due to the differences of network latencies. Most state-of-the-art techniques process out-of-order events by buffering the events until the total event order within a specified range can be guaranteed. Their main problems are leading to increasing response time and reducing system throughput. This paper aims to build a high performance out-of-order event processing mechanism, which can match events as soon as they arrive instead of buffering them till all arrive. A suffix-automaton-based event matching algorithm is proposed to speed up query processing, and a confidence-based accuracy evaluation is proposed to control the query result quality. The performance of our approach is evaluated through detailed accuracy and response time analysis. As experimental results show, our approach can obviously speed up the query matching time and produce reasonable query results.",
issn="1860-4749",
doi="10.1007/s11390-011-1168-x",
url="https://doi.org/10.1007/s11390-011-1168-x"
}
In recent years, there has been a growing need for complex event processing (CEP), ranging from supply chain management to security monitoring. In many scenarios events are generated in different sources but arrive at the central server out of order, due to the differences of network latencies. Most state-of-the-art techniques process out-of-order events by buffering the events until the total event order within a specified range can be guaranteed. Their main problems are leading to increasing response time and reducing system throughput. This paper aims to build a high performance out-of-order event processing mechanism, which can match events as soon as they arrive instead of buffering them till all arrive. A suffix-automaton-based event matching algorithm is proposed to speed up query processing, and a confidence-based accuracy evaluation is proposed to control the query result quality. The performance of our approach is evaluated through detailed accuracy and response time analysis. As experimental results show, our approach can obviously speed up the query matching time and produce reasonable query results.

@INPROCEEDINGS{S7530084, 
author={S. Chintapalli and D. Dagit and B. Evans and R. Farivar and T. Graves and M. Holderbaugh and Z. Liu and K. Nusbaum and K. Patil and B. J. Peng and P. Poulosky}, 
booktitle={2016 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
title={Benchmarking Streaming Computation Engines: Storm, Flink and Spark Streaming}, 
year={2016}, 
volume={}, 
number={}, 
pages={1789-1792}, 
abstract={Streaming data processing has been gaining attention due to its application into a wide range of scenarios. To serve the booming demands of streaming data processing, many computation engines have been developed. However, there is still a lack of real-world benchmarks that would be helpful when choosing the most appropriate platform for serving real-time streaming needs. In order to address this problem, we developed a streaming benchmark for three representative computation engines: Flink, Storm and Spark Streaming. Instead of testing speed-of-light event processing, we construct a full data pipeline using Kafka and Redis in order to more closely mimic the real-world production scenarios. Based on our experiments, we provide a performance comparison of the three data engines in terms of 99th percentile latency and throughput for various configurations.}, 
keywords={data analysis;pipeline processing;Flink streaming;Kafka;Redis;Spark streaming;Storm streaming;computation engines;data engines;data pipeline;streaming data processing;Benchmark testing;Data processing;Engines;Pipelines;Sparks;Storms;Throughput;Benchmark;Flink;Low Latency;Spark;Storm;Streaming processing}, 
doi={10.1109/IPDPSW.2016.138}, 
ISSN={}, 
month={May},}

@inproceedings{Zacheilas:2017:MDS:3093742.3093921,
 author = {Zacheilas, Nikos and Kalogeraki, Vana and Nikolakopoulos, Yiannis and Gulisano, Vincenzo and Papatriantafilou, Marina and Tsigas, Philippas},
 title = {Maximizing Determinism in Stream Processing Under Latency Constraints},
 booktitle = {Proceedings of the 11th ACM International Conference on Distributed and Event-based Systems},
 series = {DEBS '17},
 year = {2017},
 isbn = {978-1-4503-5065-5},
 location = {Barcelona, Spain},
 pages = {112--123},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/3093742.3093921},
 doi = {10.1145/3093742.3093921},
 acmid = {3093921},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Complex Event Processing, Deterministic Processing, Stream Processing},
}
The problem of coping with the demands of determinism and meeting latency constraints is challenging in distributed data stream processing systems that have to process high volume data streams that arrive from different unsynchronized input sources. In order to deterministically process the streaming data, they need mechanisms that synchronize the order in which tuples are processed by the operators. On the other hand, achieving real-time response in such a system requires careful tradeoff between determinism and low latency performance. We build on a recently proposed approach to handle data exchange and synchronization in stream processing, namely ScaleGate, which comes with guarantees for determinism and an efficient lock-free implementation, enabling high scalability. Considering the challenge and trade-offs implied by real-time constraints, we propose a system which comprises (a) a novel data structure called Slack-ScaleGate (SSG), along with its algorithmic implementation; SSG enables us to guarantee the deterministic processing of tuples as long as they are able to meet their latency constraints, and (b) a method to dynamically tune the maximum amount of time that a tuple can wait in the SSG data-structure, relaxing the determinism guarantees when needed, in order to satisfy the latency constraints. Our detailed experimental evaluation using a traffic monitoring application deployed in the city of Dublin, illustrates the working and benefits of our approach.

@ARTICLE{2015arXiv150608603C,
   author = {{Carbone}, P. and {F{\'o}ra}, G. and {Ewen}, S. and {Haridi}, S. and 
	{Tzoumas}, K.},
    title = "{Lightweight Asynchronous Snapshots for Distributed Dataflows}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1506.08603},
 primaryClass = "cs.DC",
 keywords = {Computer Science - Distributed, Parallel, and Cluster Computing},
     year = 2015,
    month = jun,
   adsurl = {http://adsabs.harvard.edu/abs/2015arXiv150608603C},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}
Distributed stateful stream processing enables the deployment and execution of large scale continuous computations in the cloud, targeting both low latency and high throughput. One of the most fundamental challenges of this paradigm is providing processing guarantees under potential failures. Existing approaches rely on periodic global state snapshots that can be used for failure recovery. Those approaches suffer from two main drawbacks. First, they often stall the overall computation which impacts ingestion. Second, they eagerly persist all records in transit along with the operation states which results in larger snapshots than required. In this work we propose Asynchronous Barrier Snapshotting (ABS), a lightweight algorithm suited for modern dataflow execution engines that minimises space requirements. ABS persists only operator states on acyclic execution topologies while keeping a minimal record log on cyclic dataflows. We implemented ABS on Apache Flink, a distributed analytics engine that supports stateful stream processing. Our evaluation shows that our algorithm does not have a heavy impact on the execution, maintaining linear scalability and performing well with frequent snapshots.

@article{Stonebraker:2005:RRS:1107499.1107504,
 author = {Stonebraker, Michael and \c{C}etintemel, U\v{g}ur and Zdonik, Stan},
 title = {The 8 Requirements of Real-time Stream Processing},
 journal = {SIGMOD Rec.},
 issue_date = {December 2005},
 volume = {34},
 number = {4},
 month = dec,
 year = {2005},
 issn = {0163-5808},
 pages = {42--47},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/1107499.1107504},
 doi = {10.1145/1107499.1107504},
 acmid = {1107504},
 publisher = {ACM},
 address = {New York, NY, USA},
} 
Applications that require real-time processing of high-volume data steams are pushing the limits of traditional data processing infrastructures. These stream-based applications include market feed processing and electronic trading on Wall Street, network and infrastructure monitoring, fraud detection, and command and control in military environments. Furthermore, as the "sea change" caused by cheap micro-sensor technology takes hold, we expect to see everything of material significance on the planet get "sensor-tagged" and report its state or location in real time. This sensorization of the real world will lead to a "green field" of novel monitoring and control applications with high-volume and low-latency processing requirements.Recently, several technologies have emerged---including off-the-shelf stream processing engines---specifically to address the challenges of processing high-volume, real-time data without requiring the use of custom code. At the same time, some existing software technologies, such as main memory DBMSs and rule engines, are also being "repurposed" by marketing departments to address these applications.In this paper, we outline eight requirements that a system software should meet to excel at a variety of real-time stream processing applications. Our goal is to provide high-level guidance to information technologists so that they will know what to look for when evaluation alternative stream processing solutions. As such, this paper serves a purpose comparable to the requirements papers in relational DBMSs and on-line analytical processing. We also briefly review alternative system software technologies in the context of our requirements.The paper attempts to be vendor neutral, so no specific commercial products are mentioned.