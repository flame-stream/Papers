%%% fs-state-related - Related work

\label {fs-related-seciton}

Many prior works in the field of stream processing do not consider consistency maintaining as a high priority task. For instance, Aurora~\cite{Abadi:2003:ANM:950481.950485} and Borealis~\cite{abadi2005design} prefer availability and low latency rather than consistency guarantees. Some other works provide only partial consistency. Apache Storm~\cite{apache:storm} supports message tracking mechanism that prevents the loss of data. However, exactly-once semantics is not provided, because duplicates are still possible. Twitter Heron, that was presented as the next generation of Apache Storm~\cite{Kulkarni:2015:THS:2723372.2742788}, does not provide for exactly once as well. Samza~\cite{Noghabi:2017:SSS:3137765.3137770} also implements fairly similar to Storm model and has the same consistency guarantees.  

One approach to achieve exactly-once semantics is to enforce determinism. As it was mentioned above, if computations are deterministic, it is fairly simple to replay input data in case of failure without producing duplicates. {\it Micro-batching} is a popular computational model that combines batch and stream processing. The main idea behind this method is to treat input data as a sequence of small-sized batches. If data items are continuously arriving, they can be packaged into batches at system's entry and then processed in a batch manner. Spark Streaming~\cite{Zaharia:2012:DSE:2342763.2342773} introduces {\it discretized streams} model that is based on micro-batching idea and is unified with Spark's batch processing. Storm Trident~\cite{apache:storm:trident} implements micro-batching on top of Apache Storm. The main advantage of the micro-batching technique is that its properties are naturally derived from batch processing model. Therefore, systems which use this approach are inherently deterministic, fault tolerant and provide strong consistency. However, such systems experience heavy overhead in terms of end-to-end latency, because of the buffering on input. Google's MillWheel~\cite{Akidau:2013:MFS:2536222.2536229} uses a different approach to make computations deterministic. It defines the order on data items and each stateful operation buffers its input before it is ensured that there are no out-of-order items up the stream. Nevertheless, extra buffering before each stateful operation can potentially lead to heavy latency overhead as well.   

Another way to provide exactly once semantics is to cope with a non-deterministic model by releasing output items only when the system is ensured that they are consistent and system's restart will not cause releasing duplicates. Apache Flink~\cite{Carbone:2017:SMA:3137765.3137777} uses the variation of Chandy-Lamport algorithm~\cite{Chandy:1985:DSD:214451.214456} for {\it state snapshotting} mechanism. This mechanism allows the system to restart processing from some determined points. However, because of the non-deterministic computational model, there is a need to take state snapshots and release output items atomically to avoid producing duplicates and the loss of data. To complete this task the adaptation of 2PC protocol for distributed transactions is used. The similar approach for exactly-once processing is applied in IBM Streams~\cite{jacques2016consistent}. The main problem regarding this method is that distributed transactions can provide significant latency overhead because output items cannot be released until the transaction is committed.  

