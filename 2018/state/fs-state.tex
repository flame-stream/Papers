\documentclass[sigconf]{acmart}
% packages should be added as needed 
\usepackage{graphicx}

\usepackage{algorithm} % for algorithms
\usepackage{algpseudocode}

\usepackage{booktabs} % For formal tables

\usepackage{amsthm} % For claims
\theoremstyle{remark}

\settopmatter{printacmref=false, printccs=false, printfolios=false}
\pagestyle{plain} % removes running headers

\newcommand{\PicScale}{0.5}
\newcommand {\FlameStream} {FlameStream}
\begin{document}

\title {Consistency guarantees for deterministic stateful stream processing}
% \titlenote{Produces the permission block, and   copyright information}
%\subtitle{Extended Abstract}
% \subtitlenote{The full version of the author's guide is available as   \texttt{acmart.pdf} document}

% \author {Igor E. Kuralenok \and Nikita Marshalkin \and Artem Trofimov \and Boris Novikov}

\author{Igor E. Kuralenok}
%\authornote{Dr.~Trovato insisted his name be first.}
%\orcid{1234-5678-9012}
\affiliation{%
  \institution{JetBrains Research}
%streetaddress{P.O. Box 1212}
  \city{St. Petersburg} 
%  \state{Ohio} 
%  \postcode{190000}
  \country{Russia}
}
\email{ikuralenok@gmail.com}

\author{Artem Trofimov}
\affiliation{%
  \institution{JetBrains Research}
  %streetaddress{P.O. Box 1212}
  \city{St. Petersburg} 
  \country{Russia}
}
\email{trofimov9artem@gmail.com}

\author{Nikita Marshalkin}
\affiliation{%
\institution{JetBrains Research}
  %streetaddress{P.O. Box 1212}
  \city{St. Petersburg} 
  \country{Russia}
}
\email{marnikitta@gmail.com}

\author{Boris Novikov}
\affiliation{%
\institution{JetBrains Research}
  %streetaddress{P.O. Box 1212}
  \city{St. Petersburg} 
  \country{Russia}
}
\email{borisnov@acm.org}


%\author{Artem Trofimov, Nikita Marshalkin, Boris Novikov}
%  \authornote{}
%\affiliation{%
%  \institution{St. Petersburg state University}
%  \streetaddress{Universitetskaya nab. 7/9}
%  \city{St. Petersburg} 
%  \postcode{199034}
% \country{Russia}
%}
%\email{trofimov9artem@gmail.com, marnikitta@gmail.com, borisnov@acm.org}


\begin{abstract}
\end {abstract}

\maketitle

\section {Introduction}
Distributed batch processing systems, such as Google's MapReduce~\cite{Dean:2008:MSD:1327452.1327492} and Apache Hadoop~\cite{hadoop2009hadoop}, addresses a need to process huge amounts of data (e.g. Internet scale). The key idea behind them is to process data blocks that have already been stored over a period of time. These systems are able to run in a massively parallel fashion on clusters consisting of thousands of commodity computational units. The main advantages of this approach are consistency, fault-recovery, and practically unlimited scalability.

However, there are a lot of scenarios where data is most valuable at its time of arrival, for example, news processing, financial analysis, network monitoring, etc. Therefore, there is a need for systems that provide low latency between event occurrence and its processing under a fixed load. Micro-batching technique, that is used in Apache Spark~\cite{Zaharia:2012:DSE:2342763.2342773} and in Storm Trident~\cite{apache:storm:trident}, inherits strong consistency properties from batch systems. It is possible to achieve the latency of several second using such systems, but it is still too high for many applications~\cite{?}.

State-of-the-art industrial distributed stream processing systems, such as Flink \cite{carbone2015apache}, Samza \cite{Noghabi:2017:SSS:3137765.3137770}, Storm \cite{apache:storm}, address this issue by providing {\it record-at-a-time} processing model. According to this model, computational units receive each record, update internal state if any, and send out new records. 

The main difficulty that stream processing systems experience is providing strong consistency. Regarding stream processing, the strongest consistency semantics is {\it exactly once}. Exactly once semantics requires that every input data item is processed only once, with or without the existence of failures. Although, such behavior is natural for batch processing systems, it is challenging for streaming systems. For instance, Samza and Storm do not support such guarantee at all, while Flink requires a complex protocol that can lead to significant latency increasing.

The key problem here is that unlike batch processing, stream processing is inherently non-deterministic. Particularly, there is no guarantee that the messages will be processed in the same order between any two runs. Therefore, it can be unclear how to determine which elements have been already released from the system after recovery to avoid duplicates. Finding the right resuming input point can be tricky as well. Additionally, if the states of operations are replicated, there is a need to determine that they are in a consistent state at the moment of taking the snapshot. 

In this paper we propose a technique to provide consistency guarantees for~\FlameStream\ - stream processing model that we designed and implemented. \FlameStream\ hides non-deterministic nature of stream processing by strong ordering assumptions. Out-of-order items are handled in an optimistic manner to avoid extra buffering. Invalid items, that can be generated by the optimistic approach, are filtered out before they leave the system. Our evaluation demonstrates that this approach has low overhead and can outperform alternative industrial solution under normal load conditions.

The order between data items is provided by meta-information that is assigned to each item. Because of the fact that processing model is deterministic, meta-information allows us to uniquely identify which data items have already left the system, from which point computations should start after recovery, and which version of the operations' state should be loaded. These features make exactly once semantics low-cost in terms of performance, that is shown in our experiments.

Therefore, the contributions of this paper are the following: 

\begin {itemize}
\item Definition of deterministic stateful streaming computational model 
\item Description of method for providing strong consistency properties within proposed model 
\item Demonstration the competitiveness of this technique
\end {itemize}

The rest of the paper is structured as follows: ...

\section {Related work}
Micro-batching. Flink's async snapshots + 2PC. Both provide high overhead. 

\section {Efficient deterministic model}
This section contains the high-level view of our model and a few implementation details.

\subsection{Data flow}
Define stream and data items.

\subsection{Computational flow}
Flow is represented in the form of a graph.

\subsection{Ordering assumptions}
The main idea: we define a total ordering on items to achieve determinism.

\subsection{Physical deployment}
The graph is deployed on each node. Hash-units, partitioning, etc.

\subsection{Supported operations}
Map/grouping and their properties.

\subsection{Stateful transformations}
Pipeline for any stateful transformation using only map and grouping. 

\subsection{Implementation notes}
In this section we describe how proposed model can be efficiently implemented without diving into details.

\section{Consistency guarantees}

Our deterministic model is able to naturally provide some consistency guarantees. We can handle package loss and node failure. Network partitioning is out of scope of stream processing.

\subsection{Package loss}
Acker determines.

\subsection{Node failure}
State can be restored.

\subsection{Barrier failure}
Barrier's state must be carefully stored.

\subsection{Contracts between system and user}
Contracts are different for at least once and exactly once. Requirements on fronts and rears.

\section {Experiments}

\subsection{Overhead and scalability}
Show that our model is scalable and provides low overhead.

\subsection{Comparison against Apache Flink}
Show that our prototype outperforms Flink with at least once/exactly once mode on. Explain such behavior.

\section {Conclusion and future work}

\bibliographystyle{ACM-Reference-Format}
\bibliography{../../bibliography/flame-stream}
\end {document}


\endinput
you can put whatever here
