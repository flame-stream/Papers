%%% fs-state-intro - Introduction

\label {fs-intro-seciton}

Distributed batch processing systems, such as Google's MapReduce~\cite{Dean:2008:MSD:1327452.1327492}, Apache Hadoop~\cite{hadoop2009hadoop}, and Apache Spark~\cite{Zaharia:2016:ASU:3013530.2934664}, address a need to process vast amounts of data (e.g., Internet-scale). The fundamental idea behind them is to independently process large data blocks that are collected from static datasets. These systems are able to run in a massively parallel fashion on clusters consisting of thousands of commodity computational units. The main advantages of these techniques are consistency, fault tolerance, and practically unlimited scalability~\cite{borthakur2011apache}.

However, there are a lot of scenarios where data is most valuable at the time of arrival, for example, IoT, news processing, financial analysis, anti-fraud, network monitoring, etc. Such problems cannot be directly addressed by classical MapReduce~\cite{Doulkeridis:2014:SLA:2628707.2628782}. State-of-the-art stream processing systems, such as Flink \cite{carbone2015apache}, Samza \cite{Noghabi:2017:SSS:3137765.3137770}, Storm \cite{apache:storm}, Spark Streaming~\cite{Zaharia:2012:DSE:2342763.2342773}, aim at filling this gap by introducing another computational model. According to this model, a system receives a record or set of records, update internal state if any, and send out new records. 

One of the most challenging task for streaming systems is to provide guarantees on data processing. Unlike batch systems, streaming ones must release output elements before processing has finished, because input data is assumed to be infinite. This requirement makes failure recovery mechanisms more complex. Streaming systems face a need to recover computations consistently with previous input data, the current system state, and, what is important, with the elements which have been already delivered to end-user. A contract regarding {\em which data} will be eventually processed and released in case of failures is usually described in terms of so-called {\em delivery guarantees}. They include {\em at most once}, {\em at least once}, and {\em exactly once}. {\it At most once} states that each input event is processed once or not processed at all. {\it At least once} guarantees that each input item is processed, but possibly multiple times. {\it Exactly once} assures that each input event is processed exactly one time. These notions are seemingly simple, but have important difficulties:

\begin{itemize}
    \item Typically, an output item depends not only on the corresponding input item but also on the system state. This fact implies that a system can {\em technically} support exactly once delivery guarantee, but in practice can release completely invalid results, because of inconsistencies in the state or in-flight elements. For example, if the state is lost or corrupted while computing the sum of all input elements, a system may continue to process input with exactly-once delivery, but the resulted sum becomes wrong. 
    \item Multiple elements can be generated from a single one inside a system. If these elements are applied to state or released non-atomically, it can lead to inconsistencies as well. Therefore, there is a need to ensure that each input element is processed together with all its derivatives. It can be illustrated as follows: assume that the system computes word counts and input elements are texts. Inside a system, each input text is split into the multiple word elements. If at least one of these elements is lost or is not applied to a system state, while others are succeeded, the result becomes incorrect. 
\end{itemize}

These examples illustrate that intuitive declarations of delivery guarantees are not sufficient to provide output consistency, while this assumption presents in most existing stream processing systems. The lack of formalization frequently causes debates and misunderstandings~\cite{JerryPengStreamIO, PaperTrail}. Without a formal model, it is hard to observe similarities and distinctions between existing solutions and to recognize their limitations.

Different stream processing systems support different delivery guarantees. The strongest and the most valuable guarantee from the user perspective is exactly once because it mitigates efforts on output consistency enforcement. Exactly once implementation is a challenging task for state-of-the-art streaming systems. For instance, Samza and Storm do not support such a guarantee at all. Flink can achieve latency in terms of milliseconds for at least once guarantee. However, for exactly once, it ensures atomicity between state updates and output elements delivery using a protocol based on distributed transactions, that leads to a significant increase of latency. Such a difference in latency between distinct types of guarantees is commonly not obvious and reduce the applicability of stream processing systems. Google MillWheel~\cite{Akidau:2013:MFS:2536222.2536229} enforces consistency between state and output elements by deduplication before each non-idempotent operation. The lower bound of latency, in this case, is the sum of disk-based deduplication durations. Micro-batching engines like Storm Trident~\cite{apache:storm:trident} and Spark Streaming~\cite{Zaharia:2012:DSE:2342763.2342773} process data in small-sized blocks. Each block is atomically processed on each stage of a dataflow that gives similar to batch processing properties. The main downside of this approach is high latency, about a few seconds~\cite{7530084, 7474816}.

Another property that is inherent for batch processing systems, but is hard to achieve in streaming engines is {\em determinism}. Determinism means that each run of the system on the same data produces the same results. Determinism is commonly considered as a challenging task~\cite{Zacheilas:2017:MDS:3093742.3093921}. On the other hand, this property is desirable, because it implies reproducibility and predictability. Intuitively, determinism is connected with consistency~\cite{Stonebraker:2005:RRS:1107499.1107504}, but, to the best of our knowledge, this relation has not been deeply investigated. 

In this work, we introduce a formal model of stream processing that captures delivery guarantees existing in several state-of-the-art systems. We show that the concepts of delivery guarantees are closely related to output data {\em consistency}, and further in this paper, we will call them {\em consistency guarantees} as well. We demonstrate that determinism is tightly connected with the consistency guarantees. An important inference of the formalism is that determinism mitigates a need for atomicity enforcement between state updates and output elements delivery for exactly once. One reason behind it, is that a deterministic system always produces the same results in case of failure and subsequent partial input replay, and these results can be deduplicated once at a system exit. This property opens a wide range for performance optimizations.

In order to prove the feasibility of efficient exactly once over determinism, we design fault tolerance protocols on top of {\em drifting state} model~\cite{we2018adbis}. Unlike naive expectations, this optimistic technique provides determinism with only a low overhead. We show that lightweight determinism together with the results of the formal inference allows achieving exactly once with almost no extra cost. It is verified by the experiments on a real-life problem.

The contributions of this paper are the following: 
\begin{itemize}
    \item Formalization of streaming delivery guarantees 
    \item Demonstration that the property of determinism is tightly related to exactly once
    \item Techniques for lightweight implementation of exactly once guarantee on top of the deterministic engine
    \item Study of practical feasibility of the proposed approaches
\end{itemize}

The rest of the paper is structured as follows: 