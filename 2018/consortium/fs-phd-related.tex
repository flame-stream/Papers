%%% fs-phd-related - State of the art
\label{fs-phd-related}

Currently, low-level and high-level consistency are mainly considered separately from each other. Modern industrial stream processing engines desire to achieve low-level consistency, especially exactly-once semantics. The area of high-level consistency is primarily discussed in research papers. In this section we review some relevant results in both directions. 

\subsection{Low-level consistency}
As it was mentioned above, there are several basic low-level guarantees: at most once, at least once, and exactly-once. At most once is the weakest guarantee, so most projects are focused on at least once and exactly-once semantics.

In most approaches, input data is replayed in case of system failures. In this case, to output only valid results, the system must recover some previously snapshotted consistent state before starting the replay. The variations of this method are implemented in Storm~\cite{apache:storm}, Heron~\cite{Kulkarni:2015:THS:2723372.2742788}, Flink~\cite{Carbone:2017:SMA:3137765.3137777}, and Samza~\cite{Noghabi:2017:SSS:3137765.3137770}. The common method to take the consistent snapshot is to periodically inject the special items into a stream. These items go along the stream as ordinary elements, but trigger taking snapshots in stateful operations. On recovery, each operation can retrieve previously snapshotted state. However, even if the recovered state of the system is consistent, duplicates can be generated. It can be explained by the fact that most stream processing models are non-deterministic, so it is hard to figure out which data elements have been already released at the moment of failure. Therefore, such approach can only guarantee at least once guarantee. 

The methods for achieving exactly-once semantics vary more. One way is to atomically take state snapshot and output items that affect the state. This technique is applied in Flink and IBM Streams~\cite{jacques2016consistent}. The atomicity is obtained using the slight modifications of the 2PC protocol, which provide high-overhead in terms of latency~\cite{we2018beyondmr}.

Another way is to apply so-called {\em strong productions}, which are introduced in Google MillWheel~\cite{Akidau:2013:MFS:2536222.2536229}. The main idea behind this method is to persistently save each input item before each operation in order to filter out duplicates. This approach makes the system idempotent, and, hence, provides for exactly-once semantics. However, accessing a persistent storage before each stateful operation can negatively influence latency and throughput.

Exactly-once also can be achieved using strong ordering on data items. Strong ordering requirements lead to deterministic processing, that can be easily converted into idempotence. Currently, this approach is adopted only by so-called {\em micro-batching} technique, that is used in Spark Streaming~\cite{Zaharia:2012:DSE:2342763.2342773} and Storm Trident~\cite{apache:storm:trident}. The main disadvantage of micro-batching is high latency due to extra buffering on input~\cite{S7530084}.

\subsection{High-level consistency}

The idea that business semantics can be effectively used in data management is not a new, e.g. in~\cite{Garcia-Molina:1983:USK:319983.319985} the methods to speed up transactions by providing only guarantees required for the particular problem are proposed. In~\cite{Guo:2010:CMS:1822018.1822052} the model for semantic consistency in communication between collaborators is motivated and discussed. The method to obtain a consistent result in a distributed database even if some nodes are inconsistent is introduced in~\cite{Rodriguez:2008:ITA:1463434.1463480}. In spite of the fact that all these papers provide interesting ideas for the topic, they are rather theoretical than practical. Therefore, it is hard to evaluate the performance of the proposed approaches.

There are several tries to adopt the ideas of semantic consistency for stream processing. In~\cite{Mihaila:2008:AIO:1458082.1458132} several higher-level consistency models are proposed and evaluated. The mechanisms to dynamically check static semantical criteria is discussed in~\cite{Fischer:2010:SSP:1739041.1739068}. Nevertheless, these solutions provide for only a limited set of predefined consistency guarantees, while we aim at completely custom user-defined consistency semantics.  