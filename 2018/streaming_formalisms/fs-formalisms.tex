\documentclass[sigconf]{acmart}

\usepackage{graphicx}
\usepackage{algorithm} % for algorithms
\usepackage{algpseudocode}
\algblockdefx[Process]{Process}{EndProcess}[2][Unknown]{{\bf Process} {\it #2}}{}
\algblockdefx[Event]{Event}{EndEvent}[2][Unknown]{{\bf upon event #2 do}}{}

\usepackage{booktabs} % For formal tables
%\usepackage{cite} %for multiple refs

\usepackage{amssymb} %for nice emptyset

\theoremstyle{remark}

\settopmatter{printacmref=false, printccs=true, printfolios=true}
\pagestyle{plain} % removes running headers

\newcommand{\PicScale}{0.5}
\newcommand {\FlameStream} {Icetream}
\begin{document}

\title {A formalization of consistency guarantees for distributed stream processing}

% \author{  Igor E. Kuralenok,$^1$     Artem Trofimov,$^ {1,2}$    Nikita Marshalkin,$^ {1,2}$   and  Boris Novikov$^ {1,2}$ }
% \affiliation{%
% \institution{$^1$JetBrains Research}
%   \city{St. Petersburg} 
%   \country{Russia}
% }
% \affiliation{%
% \institution{$^2$Saint Petersburg State University}
%   \city{St. Petersburg} 
%   \country{Russia}
% }
% \email{\string{ikuralenok, trofimov9artem, marnikitta\string}@gmail.com, borisnov@acm.org}

% \begin{abstract}
% Currently, large-scale distributed stream processing is a hot area of research. While state-of-the-art distributed stream processing systems are able to provide low-latency under at-most-once and at-least-once guarantees, achieving exactly-once semantics is still a challenging problem. An important reason behind this fact was the lack of efficient implementation techniques for idempotent stream processing model. In this work, we apply a low-overhead deterministic model to the problem of exactly-once. We demonstrate the lightweight protocols which use the property of determinism for achieving system-wide idempotence, and, therefore, exactly-once. Our experiments show that proposed approach can significantly outperform an alternative industrial solution.
% \end{abstract}

\maketitle

\section {Introduction}

In state-of-the-art stream processing systems~\cite{carbone2015apache, apache:storm, Zaharia:2016:ASU:3013530.2934664} a contract with end-user regarding ~{\em which data} will be eventually processed and released in case of failures is usually described in terms of so-called~{\em delivery guarantees}. These guarantees include {\em at most once}, {\em at least once}, and {\em exactly once}. {\it At most once} states that each input event is processed once or not processed at all. {\it At least once} guarantees that each input item is processed, but possibly multiple times, that can lead to result duplication. {\it Exactly once} assures that each input event is processed exactly one time.

The trickiest thing in these seemingly simple definitions is that output items depend not only on the corresponding input items but also on the {\em state} of dataflow operations. This fact implies that a system can {\em technically} support exactly once delivery guarantee, but in practice can release completely invalid results, because of inconsistencies in the state. State-of-the-art stream processing systems avoid state inconsistencies using complex state management mechanisms~\cite{Carbone:2017:SMA:3137765.3137777}. In terms of these systems, exactly once or at least once is not only about delivery, but is also about {\em consistency}. We believe that such meaning is much more reasonable, and further in this paper, we will call them {\em consistency guarantees}.   

However, lack of formalism in the definitions of such streaming consistency guarantees is constantly causing debates and misunderstandings~\cite{JerryPengStreamIO, PaperTrail}. In this section, we introduce mathematical definitions in order to formally describe what exactly state-of-the-art stream processing engines guarantee. We also demonstrate the main difference between our approach for achieving exactly-once and state-of-the-art in such formal language.     

\section{Formalization of consistency guarantees}

In order to make our mathematical model independent of any implementation, we consider streaming consistency guarantees as correspondences between input and output streams and the state. Hence, if we formulate guarantees only in these terms, they can be applied to any system. {\em State machine} is a natural and convenient way to express such correspondences~\cite{ссыль}. We can consider the whole stream processing system as a state machine. In this case, the state is a state of dataflow operations together with a set of items, which are being processed in the system at the moment. The events in such state machine are not only arrivals of input elements, but also such moments when input elements have been {\em nullified}. It means that the element has been completely processed or lost. However, it is unclear how to define such moments in a general case. Let us introduce some concepts, which allow us to do it.

Three basic concepts can be different for different stream processing engines. However, generality is not lost, because the specific implementation does not influence the model. The first concept is {\em entering} to the system. For example, in Flink the fact that the element has been entered means that the element has arrived at {\em source} vertex. The second notion is {\em leaving} from the system. For example, it means that element has been released to a consumer or lost. The third one is a {\em dependency}. We say that element $b$ depends on the element $a$ if $a$ has been involved in the creation of $b$. In practice, it means, e.g., that $b$ has been generated from $a$ using flat map operation. It is assumed that the states of dataflow operations are just data elements in the system, which are independent of any other elements.

Using these basic definitions, we can introduce the remaining necessary ones. Let $\tau$ be a global discrete time. Let $W_\tau$ is the set of {\em working} elements at the time $\tau$. Working elements at the time $\tau$ are the elements which have already entered the system or generated inside the system at the time $\geqslant{\tau}$, but have not left it yet. Because of the assumption that states of dataflow operations are just independent elements in the system, they are also contained in the set of working elements, i.e. if $S$ is the set of operation states, then $S\subseteq{W_\infty}$. Let $x_\tau\in{W_\tau}$ be the element, which enters at the time $\tau$, and $q_\tau\notin{W_\tau},q_\tau\in{W_{\tau-1}}$ is the element, which leaves at the time $\tau$. Let $D_{x_{\tau}}$ be the set of elements, which depend on $x_\tau$.

Having the definitions introduced above, now we can define the meaning of an element nullification. We say that element $x_\tau$ is nullified at time $\eta_{x_{\tau}}$ if $\eta_{x_{\tau}}$ is the minimal time, when $\nexists{y\in{W_{\eta_{x_{\tau}}}}}:{y}\to{x_{\tau}}$, where $\to$ is a transitive dependency. More formally, $\eta_{x_{\tau}} = inf(\hat{\tau}:\hat{\tau}\geqslant{\tau}\land{\nexists{y\in{W_{\eta_{x_{\hat{\tau}}}}}}:{y}\to{x_{\hat{\tau}}}})$. Therefore, in the proposed model events occur when an element is arrived and nullified, i.e., at times $t_i:\exists{x_{t_i}}$ and $t_o:\exists{\eta_{x_{t_o}}}$. In other words, we define time quantization for the state machine.

Now we can compare the sets of working and left elements for the cases of different input sets at some defined points in time. The main idea here is to express at most once, at least once, and exactly once guarantees as interactions between such sets. Let us construct three sets:

$X^0=(W_\infty,Q_\infty|p(W_\infty,Q_\infty|a_1...a_\infty)\neq{0})$

$X^1=(W_{\eta_{x}},Q_{\eta_{x}}|p(W_{\eta_{x}},Q_{\eta_{x}}|x,a_1...a_\infty)\neq{0},\forall{i}:{a_i}\neq{x})$

$X^{*}=(W_{\eta_{x}},Q_{\eta_{x}}|p(W_{\eta_{x}},Q_{\eta_{x}}|x,a_1...a_\infty)\neq{0},\exists{i}:{a_i={x}},\exists{y\in{W_{\eta_{x}}}}:y\to{a_i})$

$Q_\tau=\bigcup\limits_{i=1}^{\tau}{q_i}$

% Assume, that a distributed processing engine 

\bibliographystyle{ACM-Reference-Format}
\bibliography{../../bibliography/flame-stream.bib}
\end {document}

\endinput
you can put whatever here
