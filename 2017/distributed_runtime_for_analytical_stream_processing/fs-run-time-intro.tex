%%% fs-run-time-intro - Introduction

\label {fs-intro-seciton}

A need to process huge amounts of data (e.g. Internet scale) was addressed by distributed data processing systems such as Google's MapReduce~\cite{Dean:2008:MSD:1327452.1327492} and Apache Hadoop~\cite{hadoop2009hadoop}. These systems are able to run in a massively parallel fashion on clusters consisting of thousands of commodity computational units. The main advantages of this approach are fault-tolerance and practically unlimited scalability.

Several drawbacks of the initial models and architectures of this kind are deeply analyzed in~\cite{Doulkeridis:2014:SLA:2628707.2628782}. Many of these drawbacks were addressed in the next generation of scalable distributed data processing architectures, e.g. Asterix~\cite{Alsubaiee:2012:ASW:2331801.2331803}, Spark~\cite{Zaharia:2016:ASU:3013530.2934664}, 
and Flink~\cite{carbone2015apache}. 

The goal of the \FlameStream\ is to address special case of the data processing: real-time stream-based computing. This case emerges in short-term personalization, real-time analytics and other problems demanding both low update latency and flexibility of the computational subsystem. Specifically, the objectives are:

\begin {itemize}
\item Support map/reduce computations
\item Provide ``exactly once'' semantics
\item Be optimistic in terms of collision management
\item Be able to optimize computational layout based on execution statistics
\item Let the keys to get ready independently
\end {itemize}

These nice properties we trade for in-memory processing: the total state volume must be less than the total available memory of the compute units. We analyzed where the states are coming from and reshaped the operations to optimize the state management while remaining map/reduce complete. 

The optimistic collision management is done over collisions that already happen and it is often more lightweight then prevention mechanisms. This property is proided by the ability of the system to replay certain fragments of the stream. These replays demand the computation process to be deterministic. As many other systems, we use the graph representation of the computation and dynamically optimize this graph using statistics available. 

``Exactly once'' semantic is an arguable topic, we provide this guarantee inside our system but the overall contract could be violated because of source/sink flaws. To achieve this objective we introduce dynamic batching technique, based on Storm~\cite{apache:storm} ackers idea. The same mechanism allows us to get early key availability.

We follow these principles in our system architecture:
\begin{itemize}
\item The set of basic operations should not require state handling from the user. At the same time, it should provide for specification of arbitrary processing workflows, similar to those found in Spark and Flink.
\item State is the system internal term and is available to the developer as a simple coupling abstraction.
\item The processing is divided into ticks. Each tick could use different execution graph. These graphs must be equivalent in terms of the resulting stream, but can layout the computations differently.
\item The computation is deterministic: repeated processing of the same data should yield the same output.
\item Exactly once execution: each output item is valid and get out of the system exactly once even in case of partial system failures.
\end{itemize}

Enlisted principles are reflected in the following design. The computation to be performed with \FlameStream\ is specified in terms of predefined operations that are parametrized with user-defined procedures (collectively called {\em business logic} in the jargon of developers community). Each operation accepts a stream or several streams of data items, and produces one or several output streams. The whole computational workflow is described in terms of a graph. The nodes of the graph represent operations, while edges set up logical routing of data items between operations.

The \FlameStream\ runtime organizes the data items to be processed by operations into prioritized queues. The logical workflow graph is replicated to every compute unit in the cluster for scalable execution. The data items are partitioned between computational units based on user-defined hashing. This allows user to influence the computational layout and balance the load of the compute units if needed.

\FlameStream\ provides the only operation that maintains state called {\it grouping}. Grouping does not require any state management by a user. Moreover, the structure of its state can be easily made persistent, which is useful for capturing snapshots.

In this paper, we introduce the basis for an implementation of the \FlameStream\ and demonstrate advantages of the proposed system with the prototype implemented in Java on top of Akka platform. The contributions of this paper are the following:

\begin {itemize}
\item Definition of the MapReduce complete computational model without stateful user-defined procedures
\item Development of the mechanisms that provide ``exactly once'' guarantees
\item Introduce the optimistic collision management schema and demonstrate its performance competitiveness
\end {itemize}

The rest of the paper is structured as follows: in section~\ref{fs-model} we introduce the proposed computational model in details, optimistic collision management schema is described in section~\ref{fs-collision}, the implementation details of the prototype are discussed in~\ref{fs-impl} and its performance is demonstrated in~\ref{fs-experiments-section}, the main differences of our system from the existing are shown in~\ref{fs-related-section}, finally we discuss the results and our plans in~\ref{fs-conclusions}.

\endinput
