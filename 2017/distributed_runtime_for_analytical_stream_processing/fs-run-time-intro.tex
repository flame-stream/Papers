%%% fs-run-time-intro - Introduction

\label {fs-intro-seciton}

A need to process huge amounts of data (e.g. Internet scale) was addressed by distributed data processing systems such as MapReduce~\cite{Dean:2008:MSD:1327452.1327492}. These systems are able to run data processing in a massively parallel mode on a clusters consisting of thousands of commodity computational units. The main advantages of this approach are fault-tolerance and practically unlimited scalability.

However, the initial models and architectures of this kind suffered from several drawbacks are deeply analyzed in~\cite{Doulkeridis:2014:SLA:2628707.2628782}. 
Many of these drawbacks were addressed in the next generation of scalable distributed data processing architectures, e.g. 
Asterix~\cite{Alsubaiee:2012:ASW:2331801.2331803}, 
Spark~\cite{Zaharia:2016:ASU:3013530.2934664,Franklin:2015:MSB:2684822.2685326}, 
and Flink~\cite{Carbone:2017:SMA:3137765.3137777}. 

The goal of the \FlameStream ~is to address special case of the data processing: real time stream based computing. This case emerges when we talk on short term personalization, real-time analytics and other problems demanding both low update latency and flexibility of the computational subsystem. Specifically, the objectives are:

\begin {itemize}
\item Support map/reduce computations
\item Provide ``exactly once'' semantics
\item Be optimistic in terms of collision management
\item Be able to optimize computational layout based on execution statistics
\item Let the keys to get ready independently
\end {itemize}

These nice properties we trade for in-memory processing: the total state volume of the system must be less then total available memory of the compute units. To soften this restriction we have analysed where the states are coming from and how to reshape the operations to optimize the state management while being map/reduce complete. The optimistic collision management is done over collisions that already happen and it is often more lightweight then prevention mechanisms. We get this property with the ability to replay certain fragments of the stream. These replays demand the computation process to be deterministic. As many other systems we use the graph representation of the computation and dynamically optimize this graph using statistics available. ``Exactly once'' semantic is arguable topic, we provide this guarantee inside our system but the overall contract could be violated because of source/sink flaws. To get this objective fulfiled we introduce dynamic batching technique, based on Storm Ackers idea. The same mechanism lets us speak on early key availability. We follow these principles in our system architecture:
\begin{itemize}
\item The set of basic operations should not require state handling. At the same time, it should provide for specification of arbitrary processing workflows, similar to those found in Spark and Flink.
\item State is the system internal term and is provided to the developer as simple coupling abstraction
\item The processing is divided into ticks. Each tick could use different execution graph. These graphs must be equivalent in terms of the resulting stream, but layout the computation differently
\item The computation is deterministic, that is, repeated processing of the same data should yield same output
\item Exactly once execution: each output item is valid and get out of the system exactly once even in case of partial system failures
\end{itemize}

The computation to be performed with \FlameStream ~is specified in terms of predefined operations that are parametrized with user-defined procedures (collectively called {\em business logic} in the jargon of developers community). Each operation accepts a stream or several streams of data items characterized by meta-information, and produces one or several output streams. The whole computational workflow is described in terms of a graph. The nodes of the graph represent operations, while edges describe logical routing of data items between operations.

The \FlameStream ~runtime organizes the data items to be processed by operations into queues that are prioritized based on timestamps. The logical workflow graph is replicated to every computing unit in the cluster, providing for scalable execution. The data items are partitioned (shuffled, sharded) between computational units based on hashing.

In contrast with existing solutions, \FlameStream ~provides the only operation that maintains state called {\it grouping}. Notably, grouping does not require any state management by user. Moreover, the structure of its state can be easily made persistent, which is useful for capturing asynchronous snapshots.

The contributions of this paper are the following:

\begin {itemize}
\item Definition of the computational model
\item Implementation and proof of the concept
\end {itemize}

The rest of the paper is structured as follows 
Describe sections here: model~\ref {fs-model-section}
implementation~\ref{fs-implementation-section}
experiments ~\ref{fs-experiments-section}
related work~\ref{fs-related-section}.


\endinput
