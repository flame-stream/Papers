%%%% fs-run-adaptive Adaptive microbatching
\label {fs-adaptive}

In order to filter out invalid elements that are produced on grouping replay, items are collected at barrier before leaving the system. We need to find a feature that allows to differentiate items.

To archive this goal we describe the structure of meta-information that meets FlameStream timing model, defined in section~\ref{fs-data-flow}. Then, we introduce an invalidation relation on meta, that allows to distinguish proper elements from incorrect ones.

\subsubsection{Meta information}
The meta-information of data item is a pair of a {\it global time} and a trace.

\[Meta := (GlobalTime, Trace)\]

Global time is assigned to data item once the item enters the system. It is a pair of milliseconds since the epoch start and the identifier of front. The identifier is used to assign different global times to different items, even in case of wall-clock collisions. Global times are copmared by front timestamp, if they coincide - by front id. It is important to notice, that we are not relying on any synchronization between nodes' wall-clocks, but we require a strict monotonicity within single front.

\[GlobalTime := (frontTs, frontId)\]

Local time is an array of logical time of operation and the ordinal number of output item which we call {\it child id}. The logical time is simple items counter within each operation. Therefore, child id is required, because some jobs can generate multiple items from one, e.g. flat map. The items with the same child id are called {\it siblings}. When the item leaves the operation, its trace of local times is appended by new corresponding local time. The traces are compared lexicographically.

\[Trace := [LocalTime]\]
\[LocalTime := (logicalTime, childId)\]

In spite of the fact that initially there are no items with the same global time, they can be generated by some operations. The trace is used to distinguish two elements with the same global time. The main purpose of such approach is to provide information for items invalidation. 

It is worth mentioning that our concept of meta-information is similar to vector clocks
\cite{fidge1988timestamps, mattern88virtualtime}. However, unlike vector clocks, meta-information provides for the total order of data items due to the global time.

Figure~\ref{logical-graph-ops-figure} shows the topology of each operation and how it affects the trace of local times.

\begin{figure}[htbp]
  \centering
  \includegraphics[scale=0.5]{pics/operations}
  \caption{Supported operations}
  \label {logical-graph-ops-figure}
\end{figure}

Such strucure of meta allows to track different relations between data items:

\begin{enumerate}
  \item{{\it From which elements current one was produced?} From items with common trace prefix.}
  \item{{\it Which element was generated earlier?} One with lower meta.}
\end{enumerate}

Another observation is that it allows to distinguish valid elements from invalid ones.

\subsection{Invalidation relation}

Replay in grouping can generate incorrect tuples, multiple tuples with the same last item. Only one tuple from such set is correct. To find out which tuples are incorrect we introduce the invalidation relation between two data items. The main observation is that if there are two tuples with the same last elements, the one that the most recent on is more relevant that the previous one. 

The item {\it A} is said to be invalidated by the {\it B} if:

\begin{enumerate}
\item They have the same global time
\item The trace of {\it A} is lexicographically less than the trace of {\it B}
\item The first difference is in logical time
\end{enumerate}

{\it B} is called {\it invalidator} of {\it A}, or simply {\it invalidator}.

If the first difference is in child id, e.g. they were generated by broadcast operation, there is no invalidation relation between them. Hence, the invalidation relation is a partial order. 

Notice that it is defined not only for the grouping output, but for the all items. Stateless operation can not distinguish items and act on them ideltically. However, the invalidation relation cannot be lost, when item goes through other operations, because the trace of local times is append-only.

Barrier maintains a buffer of items. Once a new item arrives, it is inserted into the buffer and items that are invalidated by newcomer are removed. The pseudocode is shown in the alogorithm~\ref{buffer-insert}

\begin{algorithm}
\caption{Inserting element in buffer}
\label{buffer-insert}
\begin{algorithmic}
  \Function{INSERT}{$a$}
    \ForAll{$items \in buffer$} 
      \If{$item$ is invalidated by $a$} 
        \State \Call{dequeue}{buffer, item}
      \EndIf
    \EndFor
    \State \Call{enqueue}{a}
  \EndFunction
\end{algorithmic}
\end{algorithm}

However, there are two difficulties. The first one, barriers are deployed on multiple workers and are partitioned by the business-logic hash function. Hence, the item and corresponding invalidator can arrive to distinct barriers. As defined earlier they have the same global time, so the partitioning of barriers by global time solves this problem. Secondly, it is unclear when the items should be released from the barrier. The system should ensure that there are no in-flight invalidators. The solution of this problem is described in the next section. 

Figure~\ref{invalidation-problems-figure} illustrates possible barrier issues. Red items with labels 4 and 7 got out from the system, despite the fact that they should be invalidated by corresponding green items. 

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.48\textwidth]{pics/invalidation_problems}
  \caption{Possible barrier issues}
  \label {invalidation-problems-figure}
\end{figure}

\subsection{Minimal time within stream}
To output only correct items we need to ensure that there are no in-flight data items which can invalidate items in the barrier's buffer. In this subsection we offer sufficient condition that stream does not contain such items. Additionally, we describe how this condition is used in implementation.

\newtheorem{minimal-time-claim}{Claim}

\begin{minimal-time-claim}
Let {\it D} represent data item in barrier buffer and let {\it GT} represent its global time. If the items with global time less than or equal to {\it GT} do not exist and cannot appear in the stream, then all items that invalidate {\it D} had already arrived at the barrier buffer.
\end{minimal-time-claim}

\begin{proof}
Let {\it $D\prime$} invalidate {\it D}. According to the definition of invalidation relation, {\it $D\prime$} and {\it D} have the same global time {\it GT}, but different traces of local times. Let {\it LT} and {\it $LT\prime$} be the first distinct local times of {\it D} and {\it $D\prime$} respectively. Such difference could appear only as a result of grouping replay. Hence, {\it D} and {\it $D\prime$} are tuple items.

The global time of tuple item is inherited from the last item in the tuple, i.e. the last item in tuple {\it $D\prime$} has global time {\it GT}. Therefore, considering the properties of grouping operation, {\it $D\prime$} could be generated only if item with global time less than or equal to {\it GT} arrived at grouping. 

This implies that if stream does not contain items with global time less than or equal to {\it GT} and such items cannot appear, then all items which invalidate {\it D} had already arrived at barrier buffer. 
\end{proof}

Regarding this claim, to output item from barrier buffer we should ensure that:
\begin{enumerate}
    \item There are no items in stream with global time less than or equal to the global time of this item;
    \item Such items cannot be generated.
\end{enumerate}

To ensure that stream does not contain these items, we use agent called {\it acker}. It was inspired by Apache Storm's \cite{apache:storm} {\it acker task}. Acker tracks data item within the stream using a checksum hash. When item is sent or received by operation, its global time and checksum is sent to the acker. This message is called {\it ack}. To track elements acker groups acks by a global time into the structure called {\it ack table}. Once acker receives an ack message it updates entry by XORing new XOR with the current one. When item is sent and received by the next operation, corresponding XORs would result into zero.

To zero item's XOR only when item arrives to the barrier acks are overlapped, that is ack for receive is sent only after processing and the ack sending for transformed item. See the figure~\ref{acker}. Different colors of items means different payloads. The ack for the sending of the blue element is sent before the green's one. We expect the channel between acker and each operation FIFO, so ack for the blue item would be XORes before green's. So the two equal XORs are separated by another one. This way of ack sending guarantees that the XOR of some global time is equal to zero only if there are no elements with such lobal time.

\begin{figure}[htbp]
  \centering
  \includegraphics[scale=0.5]{pics/acker}
  \caption{Acker}
  \label {acker}
\end{figure}

Minimal global time with non-zero XOR is the minimal time within stream. On minimal time changes acker broadcasts new minimal time to the barrier and operations. Therefore, barrier can release elements with global time {\it GT} once it received notification from acker with greater {\it with GT}.

Notably, to ensure that no fronts would generate item with this timestamp, each front periodically sends to acker special message called {\it report}, which contains the least timestamp that can be assigned to data item by the front. The value in the ack table can become a zero only after corresponding report is arrived.  

\subsection{Adaptive microbatching}
The single acker with one ack table introduce a one problem. If computations are done independently by two distinct keys, without shuffling, single acker creates synthetic interrelation between them. If element with the first key arrives to the barrier it can not be released until all the elements with lower global time from another key are processed. As computation within different hash ranges can vary, this can couse additional latency.

The idea is to split single acker into multiple by some feature. This feature can be a value of data item's balancing hash, the worker would send acks to the acker with same hash range. One subtle problem is that when item changes its hash range it also needs to change an acker. This would break the FIFO ordering between operation and ackers. 

The particular feature and a way of acker changing is a topic for future research.
